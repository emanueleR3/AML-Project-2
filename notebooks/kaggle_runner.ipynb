{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AML Project 2: Federated Learning on Kaggle (All-in-One)\n",
    "\n",
    "This notebook runs the entire pipeline from Setup to Milestone 6.\n",
    "\n",
    "**Milestones:**\n",
    "- **M1-M3**: Setup, Data, Model, Central Baseline\n",
    "- **M4**: FedAvg IID\n",
    "- **M5**: Non-IID Sweep\n",
    "- **M6**: Mask Calibration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Clone Repository & Install Dependencies\n",
    "!git clone https://github.com/emanueleR3/AML-Project-2.git\n",
    "%cd AML-Project-2\n",
    "!pip install -r requirements.txt\n",
    "!pip install torch torchvision numpy matplotlib tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Imports & Setup\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('.')\n",
    "\n",
    "from src.utils import set_seed, get_device, ensure_dir, save_checkpoint, save_metrics_json, count_parameters\n",
    "from src.data import load_cifar100, create_dataloader, partition_iid, partition_non_iid\n",
    "from src.model import build_model\n",
    "from src.train import evaluate, train_one_epoch\n",
    "from src.fedavg import run_fedavg\n",
    "from src.masking import compute_sensitivity_scores, create_mask, save_mask\n",
    "\n",
    "# Setup output dirs\n",
    "OUTPUT_DIR = '/kaggle/working/outputs'\n",
    "ensure_dir(OUTPUT_DIR)\n",
    "device = get_device()\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M1-M3: Setup & Central Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DINO & Data\n",
    "print(\"Loading CIFAR-100...\")\n",
    "train_trainval, test_dataset = load_cifar100(data_dir='./data', image_size=224, download=True)\n",
    "\n",
    "# Split Train/Val\n",
    "train_size = int(0.9 * len(train_trainval))\n",
    "val_size = len(train_trainval) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "    train_trainval, [train_size, val_size], generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "# Create loaders\n",
    "val_loader = create_dataloader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = create_dataloader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "print(\"Data loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M3: Real Central Baseline\n",
    "print(\"\\nRunning Real Central Baseline...\")\n",
    "config = {\n",
    "    'model_name': 'dino_vits16',\n",
    "    'num_classes': 100,\n",
    "    'freeze_policy': 'head_only',\n",
    "    'dropout': 0.1,\n",
    "    'device': device\n",
    "}\n",
    "\n",
    "model = build_model(config)\n",
    "model.to(device)\n",
    "\n",
    "# Hyperparameters for Baseline\n",
    "epochs = 20\n",
    "eval_freq = 2\n",
    "optimizer = torch.optim.AdamW(model.get_trainable_params(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_loader = create_dataloader(train_dataset, batch_size=64, shuffle=True)\n",
    "best_acc = 0.0\n",
    "\n",
    "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss, acc = train_one_epoch(model, train_loader, optimizer, criterion, device, show_progress=False)\n",
    "    \n",
    "    # Validation logic\n",
    "    current_epoch = epoch + 1\n",
    "    if current_epoch % eval_freq == 0 or current_epoch == epochs: \n",
    "        val_loss, val_acc = evaluate(model, val_loader, criterion, device, show_progress=False)\n",
    "        \n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            save_checkpoint({'model_state_dict': model.state_dict()}, os.path.join(OUTPUT_DIR, 'central_baseline.pt'))\n",
    "            \n",
    "        print(f\"Epoch {current_epoch}/{epochs} | Train Acc: {acc:.2f}% | Val Acc: {val_acc:.2f}% | Best: {best_acc:.2f}%\")\n",
    "        \n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "\n",
    "    else:\n",
    "        print(f\"Epoch {current_epoch}/{epochs} | Train Acc: {acc:.2f}% | (Skipping Eval)\")\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    history['train_loss'].append(loss)\n",
    "    history['train_acc'].append(acc)\n",
    "\n",
    "print(f\"Baseline finished. Best Val Acc: {best_acc:.2f}%\")\n",
    "\n",
    "save_metrics_json(os.path.join(OUTPUT_DIR, 'central_baseline_metrics.json'), history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M4: FedAvg IID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "iid_config = {\n",
    "    'num_clients': 100,\n",
    "    'clients_per_round': 0.1,\n",
    "    'local_steps': 4,\n",
    "    'num_rounds': 300,\n",
    "    'batch_size': 64,\n",
    "    'lr': 0.001,\n",
    "    'weight_decay': 1e-4,\n",
    "    'seed': 42,\n",
    "    'eval_freq': 10\n",
    "}\n",
    "\n",
    "# Partition IID\n",
    "print(\"Partitioning IID...\")\n",
    "client_datasets = partition_iid(train_dataset, iid_config['num_clients'], iid_config['seed'])\n",
    "client_loaders = [create_dataloader(ds, iid_config['batch_size'], True, 0) for ds in client_datasets]\n",
    "\n",
    "# Run\n",
    "model = build_model(config)\n",
    "model.to(device)\n",
    "\n",
    "print(\"Starting FedAvg IID...\")\n",
    "history = run_fedavg(model, client_loaders, val_loader, test_loader, iid_config, device)\n",
    "\n",
    "# Save\n",
    "save_metrics_json(os.path.join(OUTPUT_DIR, 'fedavg_iid_metrics.json'), history)\n",
    "save_checkpoint({'model_state_dict': model.state_dict()}, os.path.join(OUTPUT_DIR, 'fedavg_iid_best.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M5: Non-IID Sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sweep Params\n",
    "NC_VALUES = [1, 5, 10, 50] \n",
    "J_VALUES = [4, 8, 16]      \n",
    "\n",
    "for nc in NC_VALUES:\n",
    "    for j in J_VALUES:\n",
    "        print(f\"\\n--- Runs Non-IID: Nc={nc}, J={j} ---\")\n",
    "        \n",
    "        # Partition \n",
    "        client_datasets = partition_non_iid(train_dataset, 100, nc, 42)\n",
    "        client_loaders = [create_dataloader(ds, 64, True, 0) for ds in client_datasets]\n",
    "        \n",
    "        # Config\n",
    "        sweep_config = iid_config.copy()\n",
    "        sweep_config['local_steps'] = j\n",
    "        sweep_config['num_rounds'] = 300\n",
    "        \n",
    "        # Run\n",
    "        model = build_model(config)\n",
    "        model.to(device)\n",
    "        history = run_fedavg(model, client_loaders, val_loader, test_loader, sweep_config, device)\n",
    "        \n",
    "        # Save\n",
    "        save_metrics_json(os.path.join(OUTPUT_DIR, f'noniid_nc{nc}_j{j}.json'), history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M6: Mask Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Pre-trained/Baseline Model (or use FedAvg IID result)\n",
    "# Typically we calibrate on the central baseline or FedAvg result\n",
    "print(\"Loading model for calibration...\")\n",
    "model = build_model(config)\n",
    "ckpt = torch.load(os.path.join(OUTPUT_DIR, 'central_baseline.pt')) # Using central baseline\n",
    "model.load_state_dict(ckpt['model_state_dict'])\n",
    "model.to(device)\n",
    "\n",
    "# Compute Sensitivity\n",
    "print(\"Computing sensitivity scores (Fisher)...\")\n",
    "# Use a subset of train data for calibration\n",
    "calib_loader = create_dataloader(train_dataset, 32, True)\n",
    "scores = compute_sensitivity_scores(model, calib_loader, device, num_batches=100)\n",
    "\n",
    "# Create & Save Masks\n",
    "sparsity = 0.9 # 90% sparsity\n",
    "rules = ['least_sensitive', 'random', 'highest_magnitude']\n",
    "\n",
    "for rule in rules:\n",
    "    mask = create_mask(scores, model, sparsity, rule=rule)\n",
    "    path = os.path.join(OUTPUT_DIR, f'mask_{rule}_{sparsity}.pt')\n",
    "    save_mask(mask, path)\n",
    "    print(f\"Saved mask: {rule} (Sparsity: {sparsity})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
