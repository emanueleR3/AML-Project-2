{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "header",
            "metadata": {},
            "source": [
                "# AML Project 2: Complete Sparse Federated Learning\n",
                "\n",
                "This notebook runs all sparse FedAvg experiments:\n",
                "\n",
                "**Phase 1: Ablation Studies (50 rounds each)**\n",
                "1. Calibration rounds sweep: 1, 3, 5, 10 rounds\n",
                "2. Sparsity ratio sweep: 60%, 70%, 80%, 90%\n",
                "\n",
                "**Phase 2: Final Experiments (100 rounds each)**\n",
                "- All 5 mask rules on Non-IID (Nc=1) data:\n",
                "  1. Least Sensitive\n",
                "  2. Most Sensitive\n",
                "  3. Lowest Magnitude\n",
                "  4. Highest Magnitude\n",
                "  5. Random\n",
                "- Plus: IID + Least Sensitive baseline\n",
                "\n",
                "**Estimated runtime: ~10.5 hours on T4 GPU**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "setup",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import sys\n",
                "\n",
                "# Clone repo if needed\n",
                "if not os.path.exists('AML-Project-2') and not os.path.exists('src'):\n",
                "    !git clone https://github.com/emanueleR3/AML-Project-2.git\n",
                "    %cd AML-Project-2\n",
                "\n",
                "!pip install -r requirements.txt\n",
                "!pip install torch torchvision numpy matplotlib tqdm pandas"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "imports",
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import pandas as pd\n",
                "import copy\n",
                "from tqdm import tqdm\n",
                "\n",
                "from src.utils import set_seed, get_device, ensure_dir, save_checkpoint, save_metrics_json, AverageMeter\n",
                "from src.data import load_cifar100, create_dataloader, partition_iid, partition_non_iid\n",
                "from src.model import build_model\n",
                "from src.train import evaluate\n",
                "from src.optim import SparseSGDM\n",
                "from src.sparse_fedavg import run_fedavg_sparse_round\n",
                "from src.masking import compute_sensitivity_scores, compute_fisher_diagonal, create_mask, save_mask, get_mask_sparsity\n",
                "\n",
                "sys.path.append('.')\n",
                "\n",
                "# Output directory\n",
                "OUTPUT_DIR = 'output/sparse'\n",
                "ensure_dir(OUTPUT_DIR)\n",
                "device = get_device()\n",
                "print(f\"Device: {device}\")\n",
                "\n",
                "# Model config\n",
                "config = {\n",
                "    'model_name': 'dino_vits16',\n",
                "    'num_classes': 100,\n",
                "    'freeze_policy': 'head_only',\n",
                "    'dropout': 0.1,\n",
                "    'device': device,\n",
                "    'seed': 42\n",
                "}\n",
                "\n",
                "set_seed(config['seed'])"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "data_section",
            "metadata": {},
            "source": [
                "## Load Data & Pretrained Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "load_data",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load CIFAR-100\n",
                "train_full, test_data = load_cifar100(data_dir='./data', download=True)\n",
                "\n",
                "train_size = int(0.9 * len(train_full))\n",
                "val_size = len(train_full) - train_size\n",
                "train_data, val_data = torch.utils.data.random_split(\n",
                "    train_full, [train_size, val_size],\n",
                "    generator=torch.Generator().manual_seed(42)\n",
                ")\n",
                "\n",
                "val_loader = create_dataloader(val_data, batch_size=64, shuffle=False)\n",
                "test_loader = create_dataloader(test_data, batch_size=64, shuffle=False)\n",
                "\n",
                "print(f\"Train: {len(train_data)}, Val: {len(val_data)}, Test: {len(test_data)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "load_pretrained",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load pretrained model\n",
                "baseline_path = 'output/main/central_baseline.pt'\n",
                "pretrained_state = None\n",
                "\n",
                "if os.path.exists(baseline_path):\n",
                "    ckpt = torch.load(baseline_path, map_location=device)\n",
                "    pretrained_state = ckpt['model_state_dict']\n",
                "    print(f\"✓ Loaded pretrained model from {baseline_path}\")\n",
                "else:\n",
                "    print(\"⚠ No pretrained model found, using random initialization\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "helper_section",
            "metadata": {},
            "source": [
                "## Helper Functions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "helpers",
            "metadata": {},
            "outputs": [],
            "source": [
                "def compute_multi_round_fisher(\n",
                "    model, client_loaders, device,\n",
                "    num_calibration_rounds=3,\n",
                "    clients_per_round=0.1,\n",
                "    local_steps=4,\n",
                "    lr=0.01,\n",
                "    num_batches=50\n",
                "):\n",
                "    \"\"\"Multi-round Fisher calibration (Paper [15] Sec. 4.2)\"\"\"\n",
                "    num_clients = len(client_loaders)\n",
                "    m = max(1, int(num_clients * clients_per_round))\n",
                "    \n",
                "    cumulative_fisher = None\n",
                "    model_copy = copy.deepcopy(model)\n",
                "    model_copy.to(device)\n",
                "    \n",
                "    for round_idx in range(1, num_calibration_rounds + 1):\n",
                "        selected = np.random.choice(num_clients, m, replace=False)\n",
                "        \n",
                "        # Compute Fisher from sampled clients\n",
                "        round_fisher = {n: torch.zeros_like(p) for n, p in model_copy.named_parameters() if p.requires_grad}\n",
                "        \n",
                "        for idx in selected:\n",
                "            client_fisher = compute_fisher_diagonal(model_copy, client_loaders[idx], device, num_batches=num_batches)\n",
                "            for n in round_fisher:\n",
                "                if n in client_fisher:\n",
                "                    round_fisher[n] += client_fisher[n]\n",
                "        \n",
                "        for n in round_fisher:\n",
                "            round_fisher[n] /= len(selected)\n",
                "        \n",
                "        # Accumulate\n",
                "        if cumulative_fisher is None:\n",
                "            cumulative_fisher = {n: f.clone() for n, f in round_fisher.items()}\n",
                "        else:\n",
                "            for n in cumulative_fisher:\n",
                "                cumulative_fisher[n] += round_fisher[n]\n",
                "        \n",
                "        # Update model between rounds\n",
                "        if round_idx < num_calibration_rounds:\n",
                "            temp_mask = create_mask(cumulative_fisher, model_copy, sparsity_ratio=0.8, rule='least_sensitive')\n",
                "            run_fedavg_sparse_round(\n",
                "                model_copy, client_loaders, selected.tolist(),\n",
                "                lr=lr, weight_decay=1e-4, device=device,\n",
                "                local_steps=local_steps, mask=temp_mask\n",
                "            )\n",
                "    \n",
                "    # Normalize\n",
                "    for n in cumulative_fisher:\n",
                "        cumulative_fisher[n] /= num_calibration_rounds\n",
                "    \n",
                "    return cumulative_fisher\n",
                "\n",
                "\n",
                "def run_sparse_training(\n",
                "    client_loaders, mask, num_rounds, \n",
                "    eval_freq=10, exp_name=\"exp\"\n",
                "):\n",
                "    \"\"\"Run sparse FedAvg training\"\"\"\n",
                "    model = build_model(config)\n",
                "    model.to(device)\n",
                "    if pretrained_state is not None:\n",
                "        model.load_state_dict(pretrained_state)\n",
                "    \n",
                "    num_clients = len(client_loaders)\n",
                "    m = max(1, int(num_clients * 0.1))\n",
                "    \n",
                "    history = {'round': [], 'train_acc': [], 'val_acc': [], 'test_acc': []}\n",
                "    \n",
                "    for r in range(1, num_rounds + 1):\n",
                "        selected = np.random.choice(num_clients, m, replace=False)\n",
                "        \n",
                "        loss, acc = run_fedavg_sparse_round(\n",
                "            model, client_loaders, selected.tolist(),\n",
                "            lr=0.01, weight_decay=1e-4, device=device,\n",
                "            local_steps=4, mask=mask\n",
                "        )\n",
                "        \n",
                "        if r % eval_freq == 0 or r == num_rounds:\n",
                "            val_loss, val_acc = evaluate(model, val_loader, nn.CrossEntropyLoss(), device, show_progress=False)\n",
                "            test_loss, test_acc = evaluate(model, test_loader, nn.CrossEntropyLoss(), device, show_progress=False)\n",
                "            print(f\"Round {r}/{num_rounds} | Train: {acc:.1f}% | Val: {val_acc:.1f}% | Test: {test_acc:.1f}%\")\n",
                "            \n",
                "            history['round'].append(r)\n",
                "            history['train_acc'].append(acc)\n",
                "            history['val_acc'].append(val_acc)\n",
                "            history['test_acc'].append(test_acc)\n",
                "    \n",
                "    save_metrics_json(os.path.join(OUTPUT_DIR, f'{exp_name}.json'), history)\n",
                "    return history\n",
                "\n",
                "print(\"Helper functions defined.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "phase1_header",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "# Phase 1: Ablation Studies (50 rounds each)\n",
                "\n",
                "Find optimal calibration rounds and sparsity ratio."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "iid_partition",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create IID partition for ablations\n",
                "num_clients = 100\n",
                "client_datasets_iid = partition_iid(train_data, num_clients)\n",
                "client_loaders_iid = [create_dataloader(ds, batch_size=32, shuffle=True) for ds in client_datasets_iid]\n",
                "print(f\"Created {num_clients} IID client loaders\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "calib_header",
            "metadata": {},
            "source": [
                "## 1.1 Calibration Rounds Ablation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "calib_ablation",
            "metadata": {},
            "outputs": [],
            "source": [
                "CALIB_ROUNDS = [1, 3, 5, 10]\n",
                "ABLATION_ROUNDS = 50\n",
                "FIXED_SPARSITY = 0.8\n",
                "\n",
                "calib_results = {}\n",
                "\n",
                "for num_calib in CALIB_ROUNDS:\n",
                "    print(f\"\\n{'='*50}\")\n",
                "    print(f\"Calibration Rounds = {num_calib}\")\n",
                "    print(f\"{'='*50}\")\n",
                "    \n",
                "    # Fresh model for calibration\n",
                "    model = build_model(config)\n",
                "    model.to(device)\n",
                "    if pretrained_state is not None:\n",
                "        model.load_state_dict(pretrained_state)\n",
                "    \n",
                "    # Multi-round calibration\n",
                "    fisher = compute_multi_round_fisher(\n",
                "        model, client_loaders_iid, device,\n",
                "        num_calibration_rounds=num_calib\n",
                "    )\n",
                "    \n",
                "    # Create mask\n",
                "    mask = create_mask(fisher, model, sparsity_ratio=FIXED_SPARSITY, rule='least_sensitive')\n",
                "    print(f\"Mask active ratio: {get_mask_sparsity(mask):.2%}\")\n",
                "    \n",
                "    # Train\n",
                "    history = run_sparse_training(\n",
                "        client_loaders_iid, mask, ABLATION_ROUNDS,\n",
                "        eval_freq=10, exp_name=f'ablation_calib{num_calib}'\n",
                "    )\n",
                "    \n",
                "    calib_results[num_calib] = history['test_acc'][-1]\n",
                "    print(f\"→ Final Test Acc: {calib_results[num_calib]:.2f}%\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "calib_summary",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\nCalibration Rounds Ablation Results:\")\n",
                "print(\"-\" * 30)\n",
                "for k, v in calib_results.items():\n",
                "    print(f\"  {k} rounds: {v:.2f}%\")\n",
                "\n",
                "best_calib = max(calib_results, key=calib_results.get)\n",
                "print(f\"\\n→ Best: {best_calib} calibration rounds\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "sparsity_header",
            "metadata": {},
            "source": [
                "## 1.2 Sparsity Ratio Ablation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "sparsity_ablation",
            "metadata": {},
            "outputs": [],
            "source": [
                "SPARSITY_RATIOS = [0.6, 0.7, 0.8, 0.9]\n",
                "FIXED_CALIB = 3  # Use 3 calibration rounds\n",
                "\n",
                "sparsity_results = {}\n",
                "\n",
                "# Compute Fisher once with 3 calibration rounds\n",
                "model = build_model(config)\n",
                "model.to(device)\n",
                "if pretrained_state is not None:\n",
                "    model.load_state_dict(pretrained_state)\n",
                "\n",
                "print(\"Computing Fisher with 3 calibration rounds...\")\n",
                "fisher = compute_multi_round_fisher(\n",
                "    model, client_loaders_iid, device,\n",
                "    num_calibration_rounds=FIXED_CALIB\n",
                ")\n",
                "\n",
                "for sparsity in SPARSITY_RATIOS:\n",
                "    print(f\"\\n{'='*50}\")\n",
                "    print(f\"Sparsity Ratio = {sparsity:.0%}\")\n",
                "    print(f\"{'='*50}\")\n",
                "    \n",
                "    mask = create_mask(fisher, model, sparsity_ratio=sparsity, rule='least_sensitive')\n",
                "    print(f\"Mask active ratio: {get_mask_sparsity(mask):.2%}\")\n",
                "    \n",
                "    history = run_sparse_training(\n",
                "        client_loaders_iid, mask, ABLATION_ROUNDS,\n",
                "        eval_freq=10, exp_name=f'ablation_sparsity{int(sparsity*100)}'\n",
                "    )\n",
                "    \n",
                "    sparsity_results[sparsity] = history['test_acc'][-1]\n",
                "    print(f\"→ Final Test Acc: {sparsity_results[sparsity]:.2f}%\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "sparsity_summary",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\nSparsity Ratio Ablation Results:\")\n",
                "print(\"-\" * 30)\n",
                "for k, v in sparsity_results.items():\n",
                "    print(f\"  {k:.0%}: {v:.2f}%\")\n",
                "\n",
                "best_sparsity = max(sparsity_results, key=sparsity_results.get)\n",
                "print(f\"\\n→ Best: {best_sparsity:.0%} sparsity\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "phase2_header",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "# Phase 2: Final Experiments (100 rounds each)\n",
                "\n",
                "Testing all 5 mask rules on Non-IID data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "optimal_params",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Use best parameters (or defaults if ablation didn't complete)\n",
                "OPTIMAL_CALIB = best_calib if 'best_calib' in dir() else 3\n",
                "OPTIMAL_SPARSITY = best_sparsity if 'best_sparsity' in dir() else 0.8\n",
                "\n",
                "print(f\"Optimal Parameters:\")\n",
                "print(f\"  Calibration Rounds: {OPTIMAL_CALIB}\")\n",
                "print(f\"  Sparsity Ratio: {OPTIMAL_SPARSITY:.0%}\")\n",
                "\n",
                "# Define all mask rules to test\n",
                "MASK_RULES = ['least_sensitive', 'most_sensitive', 'lowest_magnitude', 'highest_magnitude', 'random']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "noniid_partition",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create Non-IID partition (Nc=1)\n",
                "client_datasets_noniid = partition_non_iid(train_data, num_clients, num_classes_per_client=1, seed=42)\n",
                "client_loaders_noniid = [create_dataloader(ds, batch_size=32, shuffle=True) for ds in client_datasets_noniid]\n",
                "print(f\"Created {num_clients} Non-IID client loaders (Nc=1)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "compute_fisher_noniid",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compute Fisher on Non-IID data (needed for sensitivity-based masks)\n",
                "print(\"Computing Fisher scores on Non-IID data...\")\n",
                "model = build_model(config)\n",
                "model.to(device)\n",
                "if pretrained_state is not None:\n",
                "    model.load_state_dict(pretrained_state)\n",
                "\n",
                "fisher_noniid = compute_multi_round_fisher(\n",
                "    model, client_loaders_noniid, device,\n",
                "    num_calibration_rounds=OPTIMAL_CALIB\n",
                ")\n",
                "print(\"Fisher computation complete.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "exp_iid_header",
            "metadata": {},
            "source": [
                "## Experiment 1: IID + Least Sensitive (Baseline)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "exp_iid_ls",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"Experiment 1: IID + Least Sensitive Mask\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "# Calibrate on IID\n",
                "model = build_model(config)\n",
                "model.to(device)\n",
                "if pretrained_state is not None:\n",
                "    model.load_state_dict(pretrained_state)\n",
                "\n",
                "fisher_iid = compute_multi_round_fisher(\n",
                "    model, client_loaders_iid, device,\n",
                "    num_calibration_rounds=OPTIMAL_CALIB\n",
                ")\n",
                "\n",
                "mask_iid_ls = create_mask(fisher_iid, model, sparsity_ratio=OPTIMAL_SPARSITY, rule='least_sensitive')\n",
                "save_mask(mask_iid_ls, os.path.join(OUTPUT_DIR, 'mask_iid_ls.pt'))\n",
                "print(f\"Mask active ratio: {get_mask_sparsity(mask_iid_ls):.2%}\")\n",
                "\n",
                "hist_iid_ls = run_sparse_training(\n",
                "    client_loaders_iid, mask_iid_ls, 100,\n",
                "    eval_freq=10, exp_name='exp_iid_ls'\n",
                ")\n",
                "print(f\"\\n→ Final Test Accuracy: {hist_iid_ls['test_acc'][-1]:.2f}%\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "exp_noniid_header",
            "metadata": {},
            "source": [
                "## Experiments 2-6: Non-IID + All Mask Rules"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "exp_all_masks",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run all mask rules on Non-IID data\n",
                "mask_results = {}\n",
                "\n",
                "for rule_idx, rule in enumerate(MASK_RULES, start=2):\n",
                "    print(f\"\\n{'='*60}\")\n",
                "    print(f\"Experiment {rule_idx}: Non-IID (Nc=1) + {rule.replace('_', ' ').title()}\")\n",
                "    print(f\"{'='*60}\")\n",
                "    \n",
                "    # Create mask with this rule\n",
                "    mask = create_mask(fisher_noniid, model, sparsity_ratio=OPTIMAL_SPARSITY, rule=rule)\n",
                "    save_mask(mask, os.path.join(OUTPUT_DIR, f'mask_noniid_{rule}.pt'))\n",
                "    print(f\"Mask active ratio: {get_mask_sparsity(mask):.2%}\")\n",
                "    \n",
                "    # Train\n",
                "    history = run_sparse_training(\n",
                "        client_loaders_noniid, mask, 100,\n",
                "        eval_freq=10, exp_name=f'exp_noniid_{rule}'\n",
                "    )\n",
                "    \n",
                "    mask_results[rule] = history['test_acc'][-1]\n",
                "    print(f\"\\n→ Final Test Accuracy: {mask_results[rule]:.2f}%\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "results_header",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "# Results Summary"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "final_summary",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"FINAL RESULTS SUMMARY\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "print(\"\\n--- Ablation Studies (50 rounds) ---\")\n",
                "print(\"\\nCalibration Rounds:\")\n",
                "for k, v in calib_results.items():\n",
                "    marker = \"← best\" if k == best_calib else \"\"\n",
                "    print(f\"  {k} rounds: {v:.2f}% {marker}\")\n",
                "\n",
                "print(\"\\nSparsity Ratios:\")\n",
                "for k, v in sparsity_results.items():\n",
                "    marker = \"← best\" if k == best_sparsity else \"\"\n",
                "    print(f\"  {k:.0%}: {v:.2f}% {marker}\")\n",
                "\n",
                "print(\"\\n--- Final Experiments (100 rounds) ---\")\n",
                "print(f\"\\n  IID + Least Sensitive: {hist_iid_ls['test_acc'][-1]:.2f}%\")\n",
                "print(\"\\n  Non-IID (Nc=1) Mask Rule Comparison:\")\n",
                "\n",
                "# Sort by accuracy\n",
                "sorted_masks = sorted(mask_results.items(), key=lambda x: x[1], reverse=True)\n",
                "for i, (rule, acc) in enumerate(sorted_masks):\n",
                "    rank = \"★\" if i == 0 else \" \"\n",
                "    print(f\"  {rank} {rule.replace('_', ' ').title()}: {acc:.2f}%\")\n",
                "\n",
                "# Key comparison\n",
                "ls_acc = mask_results.get('least_sensitive', 0)\n",
                "rnd_acc = mask_results.get('random', 0)\n",
                "print(f\"\\n  Least Sensitive vs Random: +{ls_acc - rnd_acc:.2f} pp\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "save_all",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save complete summary\n",
                "summary = {\n",
                "    'optimal_params': {\n",
                "        'calibration_rounds': OPTIMAL_CALIB,\n",
                "        'sparsity_ratio': OPTIMAL_SPARSITY\n",
                "    },\n",
                "    'ablation_calibration': calib_results,\n",
                "    'ablation_sparsity': {str(k): v for k, v in sparsity_results.items()},\n",
                "    'final_experiments': {\n",
                "        'iid_ls': hist_iid_ls['test_acc'][-1],\n",
                "        **{f'noniid_{k}': v for k, v in mask_results.items()}\n",
                "    }\n",
                "}\n",
                "\n",
                "save_metrics_json(os.path.join(OUTPUT_DIR, 'complete_summary.json'), summary)\n",
                "print(f\"\\nResults saved to {OUTPUT_DIR}/\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "visualization",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualization\n",
                "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
                "\n",
                "# Plot 1: Calibration rounds\n",
                "ax1 = axes[0]\n",
                "ax1.bar(range(len(calib_results)), list(calib_results.values()), color='steelblue')\n",
                "ax1.set_xticks(range(len(calib_results)))\n",
                "ax1.set_xticklabels(list(calib_results.keys()))\n",
                "ax1.set_xlabel('Calibration Rounds')\n",
                "ax1.set_ylabel('Test Accuracy (%)')\n",
                "ax1.set_title('Effect of Calibration Rounds')\n",
                "ax1.grid(axis='y', alpha=0.3)\n",
                "\n",
                "# Plot 2: Sparsity ratio\n",
                "ax2 = axes[1]\n",
                "ax2.plot(list(sparsity_results.keys()), list(sparsity_results.values()), 'o-', color='darkorange', linewidth=2, markersize=8)\n",
                "ax2.set_xlabel('Sparsity Ratio')\n",
                "ax2.set_ylabel('Test Accuracy (%)')\n",
                "ax2.set_title('Effect of Sparsity Ratio')\n",
                "ax2.grid(True, alpha=0.3)\n",
                "\n",
                "# Plot 3: Mask rule comparison\n",
                "ax3 = axes[2]\n",
                "rules = list(mask_results.keys())\n",
                "accs = list(mask_results.values())\n",
                "colors = ['#2ecc71' if r == 'least_sensitive' else '#e74c3c' if r == 'random' else '#3498db' for r in rules]\n",
                "bars = ax3.bar(range(len(rules)), accs, color=colors)\n",
                "ax3.set_xticks(range(len(rules)))\n",
                "ax3.set_xticklabels([r.replace('_', '\\n') for r in rules], fontsize=9)\n",
                "ax3.set_ylabel('Test Accuracy (%)')\n",
                "ax3.set_title('Mask Rule Comparison (Non-IID)')\n",
                "ax3.grid(axis='y', alpha=0.3)\n",
                "\n",
                "# Add value labels\n",
                "for bar, acc in zip(bars, accs):\n",
                "    ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, f'{acc:.1f}', ha='center', fontsize=9)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig(os.path.join(OUTPUT_DIR, 'all_results.pdf'), bbox_inches='tight')\n",
                "plt.savefig(os.path.join(OUTPUT_DIR, 'all_results.png'), dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}