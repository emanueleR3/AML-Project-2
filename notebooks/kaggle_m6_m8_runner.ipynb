{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "7d5b84e0",
            "metadata": {},
            "source": [
                "# AML Project 2: Milestones 6-8 (Sparse Federated Learning)\n",
                "\n",
                "This notebook covers the advanced stages of the project:\n",
                "- **M6**: Mask Calibration (Fisher Information)\n",
                "- **M7**: SparseSGDM Optimizer Verification\n",
                "- **M8**: Sparse FedAvg Training (with IID/Non-IID and various Mask Rules)\n",
                "\n",
                "**Prerequisites:**\n",
                "- This notebook assumes **M3 (Central Baseline)** has been run and a checkpoint `central_baseline.pt` is available in the outputs directory.\n",
                "- Alternatively, it can run with a fresh model (but mask calibration will be random/less effective).\n",
                "\n",
                "**Note:** This notebook is configured for a **Real Experiment** scenario (100 Clients, 20 Rounds, 4 Local Steps)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Setup & Dependencies\n",
                "# Ensure we are in the project root if running locally/on Kaggle\n",
                "import os\n",
                "import sys\n",
                "\n",
                "# If running on Kaggle, clone repo if not present\n",
                "if not os.path.exists('AML-Project-2') and not os.path.exists('src'):\n",
                "    !git clone https://github.com/emanueleR3/AML-Project-2.git\n",
                "    %cd AML-Project-2\n",
                "\n",
                "# Install requirements\n",
                "!pip install -r requirements.txt\n",
                "!pip install torch torchvision numpy matplotlib tqdm"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. Imports & Configuration\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from tqdm import tqdm\n",
                "import copy\n",
                "from pathlib import Path\n",
                "\n",
                "# Add src to path\n",
                "sys.path.append('.')\n",
                "\n",
                "from src.utils import set_seed, get_device, ensure_dir, save_checkpoint, load_checkpoint, save_metrics_json, count_parameters, AverageMeter\n",
                "from src.data import load_cifar100, create_dataloader, partition_iid, partition_non_iid\n",
                "from src.model import build_model\n",
                "from src.train import evaluate, local_train\n",
                "from src.fedavg import fedavg_aggregate\n",
                "from src.optim import SparseSGDM\n",
                "from src.masking import compute_sensitivity_scores, create_mask, save_mask, load_mask, get_mask_sparsity\n",
                "\n",
                "# Setup output dirs\n",
                "OUTPUT_DIR = 'outputs'\n",
                "ensure_dir(OUTPUT_DIR)\n",
                "device = get_device()\n",
                "print(f\"Device: {device}\")\n",
                "\n",
                "# Global Config\n",
                "config = {\n",
                "    'model_name': 'dino_vits16',\n",
                "    'num_classes': 100,\n",
                "    'freeze_policy': 'head_only',\n",
                "    'dropout': 0.1,\n",
                "    'device': device,\n",
                "    'seed': 42\n",
                "}\n",
                "\n",
                "set_seed(config['seed'])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Helper Functions for Sparse FedAvg (M8 Logic)\n",
                "\n",
                "We define `client_update_sparse` and `run_fedavg_sparse_round` here since they integrate `SparseSGDM`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def client_update_sparse(\n",
                "    model: nn.Module,\n",
                "    train_loader: torch.utils.data.DataLoader,\n",
                "    lr: float,\n",
                "    weight_decay: float,\n",
                "    device: torch.device,\n",
                "    local_steps: int,\n",
                "    mask: dict,\n",
                "    criterion=None\n",
                "):\n",
                "    \"\"\"Performs local training using SparseSGDM.\"\"\"\n",
                "    local_model = copy.deepcopy(model)\n",
                "    local_model.to(device)\n",
                "    local_model.train()\n",
                "    \n",
                "    if criterion is None:\n",
                "        criterion = nn.CrossEntropyLoss()\n",
                "    \n",
                "    # Initialize SparseSGDM with the mask\n",
                "    optimizer = SparseSGDM(\n",
                "        local_model.get_trainable_params(),\n",
                "        lr=lr,\n",
                "        momentum=0.9,\n",
                "        weight_decay=weight_decay,\n",
                "        mask=mask,\n",
                "        apply_wd_to_masked_only=True\n",
                "    )\n",
                "    \n",
                "    # Run local steps\n",
                "    avg_loss, avg_acc, n_samples = local_train(\n",
                "        local_model, train_loader, optimizer, criterion, device, local_steps\n",
                "    )\n",
                "    \n",
                "    return local_model.state_dict(), avg_loss, avg_acc, n_samples\n",
                "\n",
                "\n",
                "def run_fedavg_sparse_round(\n",
                "    global_model: nn.Module,\n",
                "    client_loaders: list,\n",
                "    selected_clients: list,\n",
                "    lr: float,\n",
                "    weight_decay: float,\n",
                "    device: torch.device,\n",
                "    local_steps: int,\n",
                "    mask: dict,\n",
                "    criterion=None\n",
                "):\n",
                "    \"\"\"Run a single FedAvg round with sparse training.\"\"\"\n",
                "    client_state_dicts = []\n",
                "    client_weights = []\n",
                "    round_loss = AverageMeter()\n",
                "    round_acc = AverageMeter()\n",
                "    \n",
                "    # We can use tqdm if running interactively\n",
                "    # for client_idx in tqdm(selected_clients, desc='Clients', leave=False):\n",
                "    for client_idx in selected_clients:\n",
                "        loader = client_loaders[client_idx]\n",
                "        \n",
                "        state_dict, loss, acc, n_samples = client_update_sparse(\n",
                "            global_model, loader, lr, weight_decay, device, local_steps, mask, criterion\n",
                "        )\n",
                "        \n",
                "        client_state_dicts.append(state_dict)\n",
                "        client_weights.append(n_samples)\n",
                "        round_loss.update(loss, n_samples)\n",
                "        round_acc.update(acc, n_samples)\n",
                "    \n",
                "    # Aggregate updates into global model\n",
                "    fedavg_aggregate(global_model, client_state_dicts, client_weights)\n",
                "    \n",
                "    return round_loss.avg, round_acc.avg"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Load Data\n",
                "We load CIFAR-100 once and reuse it for creating partitions."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load full dataset\n",
                "train_full, test_data = load_cifar100(data_dir='./data', download=True)\n",
                "\n",
                "# Split Train/Val (80/20 for this stage to be safe, or match project specs)\n",
                "train_size = int(0.8 * len(train_full))\n",
                "val_size = len(train_full) - train_size\n",
                "train_data, val_data = torch.utils.data.random_split(\n",
                "    train_full, [train_size, val_size],\n",
                "    generator=torch.Generator().manual_seed(42)\n",
                ")\n",
                "\n",
                "val_loader = create_dataloader(val_data, batch_size=64, shuffle=False)\n",
                "test_loader = create_dataloader(test_data, batch_size=64, shuffle=False)\n",
                "\n",
                "print(f\"Train size: {len(train_data)}, Val size: {len(val_data)}, Test size: {len(test_data)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Milestone 6: Mask Calibration\n",
                "We calculate the Fisher Information Diagonal to estimate parameter sensitivity and create masks."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Load Baseline Model\n",
                "# Check if checkpoints exist, otherwise initialize fresh\n",
                "baseline_path = os.path.join(OUTPUT_DIR, 'central_baseline.pt')\n",
                "\n",
                "model = build_model(config)\n",
                "model.to(device)\n",
                "\n",
                "if os.path.exists(baseline_path):\n",
                "    print(f\"Loading baseline from {baseline_path}...\")\n",
                "    ckpt = torch.load(baseline_path, map_location=device)\n",
                "    model.load_state_dict(ckpt['model_state_dict'])\n",
                "else:\n",
                "    print(\"Warning: central_baseline.pt not found. Using random initialization for calibration (suboptimal).\")\n",
                "\n",
                "# 2. Calibration Data (Subset of train)\n",
                "calib_loader = create_dataloader(train_data, batch_size=32, shuffle=True)\n",
                "\n",
                "# 3. Compute Sensitivity (Fisher)\n",
                "print(\"Computing sensitivity scores...\")\n",
                "# Use 100 batches for better estimation (M8 Report recommends sufficient batches)\n",
                "scores = compute_sensitivity_scores(model, calib_loader, device, num_batches=100) \n",
                "\n",
                "# 4. Generate & Save Masks\n",
                "sparsity_ratio = 0.8\n",
                "\n",
                "rules = ['least_sensitive', 'random', 'highest_magnitude']\n",
                "masks = {}\n",
                "\n",
                "for rule in rules:\n",
                "    mask = create_mask(scores, model, sparsity_ratio=sparsity_ratio, rule=rule)\n",
                "    masks[rule] = mask\n",
                "    \n",
                "    # Save\n",
                "    path = os.path.join(OUTPUT_DIR, f'mask_{rule}_0.8.pt')\n",
                "    save_mask(mask, path)\n",
                "    \n",
                "    # Check sparsity (fraction of 1s)\n",
                "    active_ratio = get_mask_sparsity(mask)\n",
                "    print(f\"Rule: {rule} | Active params: {active_ratio:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Milestone 7: SparseSGDM Verification\n",
                "We verify that the `SparseSGDM` optimizer correctly updates only the unmasked parameters.\n",
                "**Expectation**: Masked parameters (mask=0) should NOT change. Active parameters (mask=1) SHOULD change."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"--- Testing SparseSGDM ---\")\n",
                "# Create a dummy model and mask\n",
                "dummy_model = nn.Linear(10, 1)\n",
                "dummy_mask = {\n",
                "    'weight': torch.cat([torch.ones(1, 5), torch.zeros(1, 5)], dim=1), # First 5 active, last 5 masked (0)\n",
                "    'bias': torch.ones(1)\n",
                "}\n",
                "\n",
                "optimizer = SparseSGDM(dummy_model.parameters(), lr=0.1, mask=dummy_mask)\n",
                "\n",
                "initial_weight = dummy_model.weight.data.clone()\n",
                "\n",
                "# Artificial gradient\n",
                "dummy_model.weight.grad = torch.ones_like(dummy_model.weight)\n",
                "dummy_model.bias.grad = torch.ones_like(dummy_model.bias)\n",
                "\n",
                "optimizer.step()\n",
                "\n",
                "updated_weight = dummy_model.weight.data\n",
                "diff = (updated_weight - initial_weight).abs()\n",
                "\n",
                "print(f\"Initial Weights (first 5 active): {initial_weight[0, :5]}\")\n",
                "print(f\"Initial Weights (last 5 masked):  {initial_weight[0, 5:]}\")\n",
                "print(\"-\" * 30)\n",
                "print(f\"Updated Weights (first 5 active): {updated_weight[0, :5]}\")\n",
                "print(f\"Updated Weights (last 5 masked):  {updated_weight[0, 5:]}\")\n",
                "print(\"-\" * 30)\n",
                "print(f\"Difference (first 5): {diff[0, :5]}\")\n",
                "print(f\"Difference (last 5):  {diff[0, 5:]}\")\n",
                "\n",
                "# Verification Logic\n",
                "if torch.all(diff[0, 5:] == 0) and torch.any(diff[0, :5] > 0):\n",
                "    print(\"\\n✅ PASS: Masked parameters remained unchanged, active parameters updated.\")\n",
                "else:\n",
                "    print(\"\\n❌ FAIL: Optimization behavior incorrect.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Milestone 8: Sparse FedAvg Experiments (Real Experiment)\n",
                "\n",
                "We run 3 experiments to compare performance. \n",
                "**Configuration (Real Experiment):**\n",
                "- `num_clients`: 100\n",
                "- `clients_per_round`: 10 (0.1)\n",
                "- `local_steps`: 4 (J=4)\n",
                "- `num_rounds`: 20 (Set to 20-50 for convergence, kept to 20 for Kaggle runtime feasibility)\n",
                "\n",
                "**Experiments:**\n",
                "1. **IID** with `least_sensitive` mask\n",
                "2. **Non-IID (Nc=1)** with `least_sensitive` mask\n",
                "3. **Non-IID (Nc=1)** with `random` mask (Extension)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Common Training Loop Function\n",
                "def run_experiment(exp_name, is_iid, nc, mask_rule, num_rounds=20):\n",
                "    print(f\"\\n>>> Starting Experiment: {exp_name} <<<\")\n",
                "    print(f\"Settings: IID={is_iid}, Nc={nc}, Mask={mask_rule}, Rounds={num_rounds}\")\n",
                "    \n",
                "    # 1. Partition Data (Real Scale: K=100)\n",
                "    num_clients = 100 \n",
                "    if is_iid:\n",
                "        client_datasets = partition_iid(train_data, num_clients)\n",
                "    else:\n",
                "        client_datasets = partition_non_iid(train_data, num_clients, nc=nc)\n",
                "        \n",
                "    client_loaders = [create_dataloader(ds, batch_size=32, shuffle=True) for ds in client_datasets]\n",
                "    \n",
                "    # 2. Setup Model & Mask\n",
                "    model = build_model(config)\n",
                "    model.to(device)\n",
                "    \n",
                "    # Load appropriate mask\n",
                "    mask = masks[mask_rule] # From previous cell\n",
                "    \n",
                "    # 3. Training Loop\n",
                "    clients_per_round = 0.1 # 10 clients\n",
                "    m = max(1, int(num_clients * clients_per_round))\n",
                "    \n",
                "    history = {'round': [], 'val_acc': [], 'test_acc': []}\n",
                "    \n",
                "    for r in range(1, num_rounds + 1):\n",
                "        selected_clients = np.random.choice(num_clients, m, replace=False)\n",
                "        \n",
                "        loss, acc = run_fedavg_sparse_round(\n",
                "            model, client_loaders, selected_clients,\n",
                "            lr=0.01, weight_decay=1e-4, device=device,\n",
                "            local_steps=4, # J=4 (Real standard)\n",
                "            mask=mask\n",
                "        )\n",
                "        \n",
                "        # Validate\n",
                "        if r % 2 == 0 or r == num_rounds: # Eval every 2 rounds\n",
                "            val_loss, val_acc = evaluate(model, val_loader, nn.CrossEntropyLoss(), device, show_progress=False)\n",
                "            test_loss, test_acc = evaluate(model, test_loader, nn.CrossEntropyLoss(), device, show_progress=False)\n",
                "            print(f\"Round {r}: TrainAcc={acc:.2f}%, ValAcc={val_acc:.2f}%, TestAcc={test_acc:.2f}%\")\n",
                "            \n",
                "            history['round'].append(r)\n",
                "            history['val_acc'].append(val_acc)\n",
                "            history['test_acc'].append(test_acc)\n",
                "        else:\n",
                "            print(f\"Round {r}: TrainAcc={acc:.2f}%\")\n",
                "        \n",
                "    # Save metrics\n",
                "    save_metrics_json(os.path.join(OUTPUT_DIR, f'{exp_name}_metrics.json'), history)\n",
                "    return history"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Experiment 1: IID + Least Sensitive\n",
                "hist_iid = run_experiment('exp_iid_ls', is_iid=True, nc=None, mask_rule='least_sensitive', num_rounds=20)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Experiment 2: Non-IID (Nc=1) + Least Sensitive\n",
                "hist_niid_ls = run_experiment('exp_niid_ls', is_iid=False, nc=1, mask_rule='least_sensitive', num_rounds=20)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Experiment 3: Non-IID (Nc=1) + Random Mask (Extension)\n",
                "hist_niid_rnd = run_experiment('exp_niid_rnd', is_iid=False, nc=1, mask_rule='random', num_rounds=20)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Results Visualization\n",
                "Comparison of Validation Accuracy across different settings."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(10, 6))\n",
                "plt.plot(hist_iid['round'], hist_iid['val_acc'], marker='o', label='IID (Least Sens)')\n",
                "plt.plot(hist_niid_ls['round'], hist_niid_ls['val_acc'], marker='s', label='Non-IID Nc=1 (Least Sens)')\n",
                "plt.plot(hist_niid_rnd['round'], hist_niid_rnd['val_acc'], marker='^', linestyle='--', label='Non-IID Nc=1 (Random)')\n",
                "\n",
                "plt.title('Sparse FedAvg Performance Comparison')\n",
                "plt.xlabel('Round')\n",
                "plt.ylabel('Validation Accuracy (%)')\n",
                "plt.grid(True)\n",
                "plt.legend()\n",
                "plt.savefig(os.path.join(OUTPUT_DIR, 'sparse_fedavg_comparison.png'))\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
