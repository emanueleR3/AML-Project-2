{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Milestone M5 — Non-IID + Sweep on Nc and J\n",
                "\n",
                "**Goal**: Study the effect of non-IID data heterogeneity and local steps on FedAvg performance.\n",
                "\n",
                "## Experiment Configuration\n",
                "- **K** = 100 clients\n",
                "- **C** = 0.1 (10 clients per round)\n",
                "- **Nc** ∈ {1, 5, 10, 50} (classes per client)\n",
                "- **J** ∈ {4, 8, 16} (local steps)\n",
                "- Fixed number of rounds for fair comparison"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import json\n",
                "import copy\n",
                "import numpy as np\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import matplotlib.pyplot as plt\n",
                "from itertools import product\n",
                "from tqdm import tqdm\n",
                "\n",
                "# Import utilities\n",
                "from src.utils import set_seed, get_device, ensure_dir, save_checkpoint, save_metrics_json\n",
                "from src.data import load_cifar100, create_dataloader, partition_non_iid, get_transforms\n",
                "from src.model import build_model\n",
                "from src.train import evaluate\n",
                "from src.fedavg import run_fedavg"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Base configuration\n",
                "base_config = {\n",
                "    'exp_name': 'fedavg_noniid_sweep',\n",
                "    'seed': 42,\n",
                "    'data_dir': './data',\n",
                "    'output_dir': './outputs',\n",
                "    \n",
                "    # Model\n",
                "    'model_name': 'dino_vits16',\n",
                "    'num_classes': 100,\n",
                "    'freeze_policy': 'head_only',\n",
                "    'dropout': 0.0,\n",
                "    \n",
                "    # FL settings\n",
                "    'num_clients': 100,          # K\n",
                "    'clients_per_round': 0.1,    # C\n",
                "    'num_rounds': 50,            # Fixed rounds for comparison\n",
                "    \n",
                "    # Training\n",
                "    'batch_size': 32,\n",
                "    'lr': 0.01,\n",
                "    'weight_decay': 1e-4,\n",
                "    'num_workers': 0,\n",
                "}\n",
                "\n",
                "# Sweep parameters\n",
                "NC_VALUES = [1, 5, 10, 50]   # Classes per client\n",
                "J_VALUES = [4, 8, 16]        # Local steps\n",
                "\n",
                "# Set seed and device\n",
                "set_seed(base_config['seed'])\n",
                "device = get_device()\n",
                "print(f\"Device: {device}\")\n",
                "print(f\"Sweep: Nc ∈ {NC_VALUES}, J ∈ {J_VALUES}\")\n",
                "print(f\"Total experiments: {len(NC_VALUES) * len(J_VALUES)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Setup Output Directories"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create output directories\n",
                "sweep_dir = os.path.join(base_config['output_dir'], 'logs', base_config['exp_name'])\n",
                "figures_dir = os.path.join(base_config['output_dir'], 'figures')\n",
                "checkpoint_dir = os.path.join(base_config['output_dir'], 'checkpoints')\n",
                "\n",
                "ensure_dir(sweep_dir)\n",
                "ensure_dir(figures_dir)\n",
                "ensure_dir(checkpoint_dir)\n",
                "\n",
                "print(f\"Sweep results: {sweep_dir}\")\n",
                "print(f\"Figures: {figures_dir}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Load Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Loading CIFAR-100...\")\n",
                "train_dataset, test_dataset = load_cifar100(data_dir=base_config['data_dir'], image_size=224)\n",
                "\n",
                "# Split train into train/val\n",
                "train_size = int(0.9 * len(train_dataset))\n",
                "val_size = len(train_dataset) - train_size\n",
                "train_subset, val_subset = torch.utils.data.random_split(\n",
                "    train_dataset,\n",
                "    [train_size, val_size],\n",
                "    generator=torch.Generator().manual_seed(base_config['seed'])\n",
                ")\n",
                "\n",
                "# Create val and test loaders (these are shared across experiments)\n",
                "val_loader = create_dataloader(val_subset, batch_size=base_config['batch_size'], shuffle=False, num_workers=base_config['num_workers'])\n",
                "test_loader = create_dataloader(test_dataset, batch_size=base_config['batch_size'], shuffle=False, num_workers=base_config['num_workers'])\n",
                "\n",
                "print(f\"Train: {len(train_subset)}, Val: {len(val_subset)}, Test: {len(test_dataset)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Run Sweep Experiments"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def run_experiment(nc: int, j: int, train_dataset, val_loader, test_loader, base_config, device):\n",
                "    \"\"\"\n",
                "    Run a single FedAvg experiment with given Nc and J.\n",
                "    \"\"\"\n",
                "    print(f\"\\n{'='*60}\")\n",
                "    print(f\"Running experiment: Nc={nc}, J={j}\")\n",
                "    print(f\"{'='*60}\")\n",
                "    \n",
                "    # Reset seed for reproducibility\n",
                "    set_seed(base_config['seed'])\n",
                "    \n",
                "    # Partition data (non-IID)\n",
                "    print(f\"Partitioning data: {base_config['num_clients']} clients, {nc} classes each...\")\n",
                "    client_datasets = partition_non_iid(\n",
                "        train_dataset,\n",
                "        num_clients=base_config['num_clients'],\n",
                "        num_classes_per_client=nc,\n",
                "        seed=base_config['seed']\n",
                "    )\n",
                "    \n",
                "    # Create client loaders\n",
                "    client_loaders = [\n",
                "        create_dataloader(ds, batch_size=base_config['batch_size'], shuffle=True, num_workers=0)\n",
                "        for ds in client_datasets\n",
                "    ]\n",
                "    \n",
                "    # Build fresh model\n",
                "    model = build_model(base_config)\n",
                "    model.to(device)\n",
                "    \n",
                "    # Run FedAvg\n",
                "    config = {\n",
                "        **base_config,\n",
                "        'local_steps': j,\n",
                "        'nc': nc,\n",
                "    }\n",
                "    \n",
                "    history = run_fedavg(\n",
                "        global_model=model,\n",
                "        client_loaders=client_loaders,\n",
                "        val_loader=val_loader,\n",
                "        test_loader=test_loader,\n",
                "        config=config,\n",
                "        device=device\n",
                "    )\n",
                "    \n",
                "    # Add experiment info to history\n",
                "    history['nc'] = nc\n",
                "    history['local_steps'] = j\n",
                "    history['config'] = config\n",
                "    \n",
                "    return history"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run all experiments\n",
                "all_results = {}\n",
                "\n",
                "for nc in NC_VALUES:\n",
                "    for j in J_VALUES:\n",
                "        exp_key = f\"nc{nc}_j{j}\"\n",
                "        \n",
                "        # Run experiment\n",
                "        history = run_experiment(\n",
                "            nc=nc, j=j,\n",
                "            train_dataset=train_dataset,  # Use original train dataset for partitioning\n",
                "            val_loader=val_loader,\n",
                "            test_loader=test_loader,\n",
                "            base_config=base_config,\n",
                "            device=device\n",
                "        )\n",
                "        \n",
                "        all_results[exp_key] = history\n",
                "        \n",
                "        # Save individual experiment results\n",
                "        exp_path = os.path.join(sweep_dir, f'{exp_key}_metrics.json')\n",
                "        \n",
                "        # Convert to serializable format\n",
                "        save_data = {\n",
                "            k: v if not isinstance(v, dict) else {str(kk): vv for kk, vv in v.items()}\n",
                "            for k, v in history.items()\n",
                "        }\n",
                "        save_metrics_json(exp_path, save_data)\n",
                "        print(f\"Saved results to {exp_path}\")\n",
                "\n",
                "print(f\"\\n{'='*60}\")\n",
                "print(\"All experiments completed!\")\n",
                "print(f\"{'='*60}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Results Table (Nc × J)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create results table\n",
                "print(\"\\n\" + \"=\"*70)\n",
                "print(\"RESULTS TABLE: Final Test Accuracy (%)\")\n",
                "print(\"=\"*70)\n",
                "\n",
                "# Header\n",
                "header = \"Nc\\\\J   |\" + \" | \".join([f\"  J={j:2d}  \" for j in J_VALUES]) + \" |\"\n",
                "print(header)\n",
                "print(\"-\" * len(header))\n",
                "\n",
                "# Results matrix\n",
                "results_matrix = []\n",
                "for nc in NC_VALUES:\n",
                "    row = []\n",
                "    row_str = f\"Nc={nc:2d}  |\"\n",
                "    for j in J_VALUES:\n",
                "        exp_key = f\"nc{nc}_j{j}\"\n",
                "        if exp_key in all_results:\n",
                "            final_test_acc = all_results[exp_key]['test_acc'][-1]\n",
                "            row.append(final_test_acc)\n",
                "            row_str += f\" {final_test_acc:6.2f}% |\"\n",
                "        else:\n",
                "            row.append(None)\n",
                "            row_str += \"    N/A |\"\n",
                "    results_matrix.append(row)\n",
                "    print(row_str)\n",
                "\n",
                "print(\"=\"*70)\n",
                "\n",
                "# Best Val Accuracy Table\n",
                "print(\"\\n\" + \"=\"*70)\n",
                "print(\"RESULTS TABLE: Best Validation Accuracy (%)\")\n",
                "print(\"=\"*70)\n",
                "print(header)\n",
                "print(\"-\" * len(header))\n",
                "\n",
                "for nc in NC_VALUES:\n",
                "    row_str = f\"Nc={nc:2d}  |\"\n",
                "    for j in J_VALUES:\n",
                "        exp_key = f\"nc{nc}_j{j}\"\n",
                "        if exp_key in all_results:\n",
                "            best_val_acc = all_results[exp_key].get('best_val_acc', max(all_results[exp_key]['val_acc']))\n",
                "            row_str += f\" {best_val_acc:6.2f}% |\"\n",
                "        else:\n",
                "            row_str += \"    N/A |\"\n",
                "    print(row_str)\n",
                "\n",
                "print(\"=\"*70)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Visualization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot 1: Test accuracy curves for all experiments\n",
                "fig, axes = plt.subplots(1, len(NC_VALUES), figsize=(16, 4), sharey=True)\n",
                "\n",
                "colors = plt.cm.viridis(np.linspace(0, 0.8, len(J_VALUES)))\n",
                "\n",
                "for ax_idx, nc in enumerate(NC_VALUES):\n",
                "    ax = axes[ax_idx]\n",
                "    for j_idx, j in enumerate(J_VALUES):\n",
                "        exp_key = f\"nc{nc}_j{j}\"\n",
                "        if exp_key in all_results:\n",
                "            rounds = all_results[exp_key]['round']\n",
                "            test_acc = all_results[exp_key]['test_acc']\n",
                "            ax.plot(rounds, test_acc, label=f'J={j}', color=colors[j_idx], linewidth=2)\n",
                "    \n",
                "    ax.set_title(f'Nc = {nc}', fontsize=12, fontweight='bold')\n",
                "    ax.set_xlabel('Round', fontsize=10)\n",
                "    if ax_idx == 0:\n",
                "        ax.set_ylabel('Test Accuracy (%)', fontsize=10)\n",
                "    ax.legend(loc='lower right')\n",
                "    ax.grid(True, alpha=0.3)\n",
                "\n",
                "plt.suptitle('FedAvg Test Accuracy: Effect of Nc and J', fontsize=14, fontweight='bold')\n",
                "plt.tight_layout()\n",
                "\n",
                "curve_path = os.path.join(figures_dir, 'fedavg_noniid_curves.png')\n",
                "plt.savefig(curve_path, dpi=150, bbox_inches='tight')\n",
                "print(f\"Saved curves to: {curve_path}\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot 2: Heatmap of final test accuracy\n",
                "import numpy as np\n",
                "\n",
                "# Build matrix\n",
                "acc_matrix = np.zeros((len(NC_VALUES), len(J_VALUES)))\n",
                "for i, nc in enumerate(NC_VALUES):\n",
                "    for k, j in enumerate(J_VALUES):\n",
                "        exp_key = f\"nc{nc}_j{k}\"\n",
                "        if exp_key in all_results:\n",
                "            acc_matrix[i, k] = all_results[exp_key]['test_acc'][-1]\n",
                "\n",
                "fig, ax = plt.subplots(figsize=(8, 6))\n",
                "im = ax.imshow(acc_matrix, cmap='YlGnBu', aspect='auto')\n",
                "\n",
                "# Labels\n",
                "ax.set_xticks(range(len(J_VALUES)))\n",
                "ax.set_xticklabels([f'J={j}' for j in J_VALUES])\n",
                "ax.set_yticks(range(len(NC_VALUES)))\n",
                "ax.set_yticklabels([f'Nc={nc}' for nc in NC_VALUES])\n",
                "ax.set_xlabel('Local Steps (J)', fontsize=12)\n",
                "ax.set_ylabel('Classes per Client (Nc)', fontsize=12)\n",
                "ax.set_title('Final Test Accuracy (%)', fontsize=14, fontweight='bold')\n",
                "\n",
                "# Add values to cells\n",
                "for i in range(len(NC_VALUES)):\n",
                "    for k in range(len(J_VALUES)):\n",
                "        text = ax.text(k, i, f'{acc_matrix[i, k]:.1f}',\n",
                "                       ha='center', va='center', color='black', fontsize=11)\n",
                "\n",
                "plt.colorbar(im, ax=ax, label='Accuracy (%)')\n",
                "plt.tight_layout()\n",
                "\n",
                "heatmap_path = os.path.join(figures_dir, 'fedavg_noniid_heatmap.png')\n",
                "plt.savefig(heatmap_path, dpi=150, bbox_inches='tight')\n",
                "print(f\"Saved heatmap to: {heatmap_path}\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot 3: Effect of Nc (fixed J values)\n",
                "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
                "\n",
                "# Left: Lines for each J value showing Nc effect\n",
                "ax = axes[0]\n",
                "for j_idx, j in enumerate(J_VALUES):\n",
                "    accs = []\n",
                "    for nc in NC_VALUES:\n",
                "        exp_key = f\"nc{nc}_j{j}\"\n",
                "        if exp_key in all_results:\n",
                "            accs.append(all_results[exp_key]['test_acc'][-1])\n",
                "        else:\n",
                "            accs.append(np.nan)\n",
                "    ax.plot(NC_VALUES, accs, marker='o', label=f'J={j}', linewidth=2, markersize=8)\n",
                "\n",
                "ax.set_xlabel('Classes per Client (Nc)', fontsize=12)\n",
                "ax.set_ylabel('Final Test Accuracy (%)', fontsize=12)\n",
                "ax.set_title('Effect of Non-IID Severity', fontsize=12, fontweight='bold')\n",
                "ax.legend()\n",
                "ax.grid(True, alpha=0.3)\n",
                "ax.set_xscale('log')\n",
                "ax.set_xticks(NC_VALUES)\n",
                "ax.set_xticklabels(NC_VALUES)\n",
                "\n",
                "# Right: Lines for each Nc value showing J effect\n",
                "ax = axes[1]\n",
                "for nc_idx, nc in enumerate(NC_VALUES):\n",
                "    accs = []\n",
                "    for j in J_VALUES:\n",
                "        exp_key = f\"nc{nc}_j{j}\"\n",
                "        if exp_key in all_results:\n",
                "            accs.append(all_results[exp_key]['test_acc'][-1])\n",
                "        else:\n",
                "            accs.append(np.nan)\n",
                "    ax.plot(J_VALUES, accs, marker='s', label=f'Nc={nc}', linewidth=2, markersize=8)\n",
                "\n",
                "ax.set_xlabel('Local Steps (J)', fontsize=12)\n",
                "ax.set_ylabel('Final Test Accuracy (%)', fontsize=12)\n",
                "ax.set_title('Effect of Local Steps', fontsize=12, fontweight='bold')\n",
                "ax.legend()\n",
                "ax.grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "\n",
                "effect_path = os.path.join(figures_dir, 'fedavg_noniid_effects.png')\n",
                "plt.savefig(effect_path, dpi=150, bbox_inches='tight')\n",
                "print(f\"Saved effects plot to: {effect_path}\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Save Summary Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save all results summary\n",
                "summary = {\n",
                "    'nc_values': NC_VALUES,\n",
                "    'j_values': J_VALUES,\n",
                "    'experiments': {}\n",
                "}\n",
                "\n",
                "for exp_key, history in all_results.items():\n",
                "    summary['experiments'][exp_key] = {\n",
                "        'nc': history['nc'],\n",
                "        'local_steps': history['local_steps'],\n",
                "        'final_test_acc': history['test_acc'][-1],\n",
                "        'best_val_acc': history.get('best_val_acc', max(history['val_acc'])),\n",
                "        'final_val_acc': history['val_acc'][-1],\n",
                "    }\n",
                "\n",
                "summary_path = os.path.join(sweep_dir, 'sweep_summary.json')\n",
                "save_metrics_json(summary_path, summary)\n",
                "print(f\"Saved summary to: {summary_path}\")\n",
                "\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"SWEEP COMPLETE!\")\n",
                "print(\"=\"*60)\n",
                "print(f\"Results saved to: {sweep_dir}\")\n",
                "print(f\"Figures saved to: {figures_dir}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}