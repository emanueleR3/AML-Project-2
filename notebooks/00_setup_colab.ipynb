{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "a1b2c3d4",
            "metadata": {},
            "source": [
                "# Setup - Download DINO ViT-S/16 and CIFAR-100\n",
                "\n",
                "This notebook downloads:\n",
                "1. **DINO ViT-S/16** model from the official Facebook Research repository\n",
                "2. **CIFAR-100** dataset using torchvision"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b2c3d4e5",
            "metadata": {},
            "source": [
                "## 1. Install Required Dependencies"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c3d4e5f6",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\u001b[31m\n",
                        "\u001b[0m"
                    ]
                }
            ],
            "source": [
                "# Install required packages (run if needed)\n",
                "#!pip install -q -r requirements.txt"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "id": "d4e5f6g7",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "PyTorch version: 2.9.0+cpu\n",
                        "Torchvision version: 0.24.0+cpu\n",
                        "CUDA available: False\n"
                    ]
                }
            ],
            "source": [
                "import torch\n",
                "import torchvision\n",
                "import torchvision.transforms as transforms\n",
                "\n",
                "print(f\"PyTorch version: {torch.__version__}\")\n",
                "print(f\"Torchvision version: {torchvision.__version__}\")\n",
                "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e5f6g7h8",
            "metadata": {},
            "source": [
                "## 2. Download DINO ViT-S/16 Model\n",
                "\n",
                "Loading the pretrained DINO ViT-S/16 model from the official Facebook Research GitHub repository:\n",
                "https://github.com/facebookresearch/dino"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "id": "f6g7h8i9",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Downloading DINO ViT-S/16 model...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Using cache found in /root/.cache/torch/hub/facebookresearch_dino_main\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "DINO ViT-S/16 model loaded successfully!\n",
                        "Model architecture:\n",
                        "VisionTransformer(\n",
                        "  (patch_embed): PatchEmbed(\n",
                        "    (proj): Conv2d(3, 384, kernel_size=(16, 16), stride=(16, 16))\n",
                        "  )\n",
                        "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
                        "  (blocks): ModuleList(\n",
                        "    (0-11): 12 x Block(\n",
                        "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
                        "      (attn): Attention(\n",
                        "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
                        "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
                        "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
                        "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
                        "      )\n",
                        "      (drop_path): Identity()\n",
                        "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
                        "      (mlp): Mlp(\n",
                        "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
                        "        (act): GELU(approximate='none')\n",
                        "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
                        "        (drop): Dropout(p=0.0, inplace=False)\n",
                        "      )\n",
                        "    )\n",
                        "  )\n",
                        "  (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
                        "  (head): Identity()\n",
                        ")\n"
                    ]
                }
            ],
            "source": [
                "# Load DINO ViT-S/16 pretrained model from Facebook Research repository\n",
                "print(\"Downloading DINO ViT-S/16 model...\")\n",
                "\n",
                "dino_vits16 = torch.hub.load('facebookresearch/dino:main', 'dino_vits16')\n",
                "\n",
                "# Set model to evaluation mode\n",
                "dino_vits16.eval()\n",
                "\n",
                "print(\"\\nDINO ViT-S/16 model loaded successfully!\")\n",
                "print(f\"Model architecture:\\n{dino_vits16}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "id": "g7h8i9j0",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Total parameters: 21,665,664\n",
                        "Trainable parameters: 21,665,664\n"
                    ]
                }
            ],
            "source": [
                "# Model information\n",
                "total_params = sum(p.numel() for p in dino_vits16.parameters())\n",
                "trainable_params = sum(p.numel() for p in dino_vits16.parameters() if p.requires_grad)\n",
                "\n",
                "print(f\"Total parameters: {total_params:,}\")\n",
                "print(f\"Trainable parameters: {trainable_params:,}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "h8i9j0k1",
            "metadata": {},
            "source": [
                "## 3. Download CIFAR-100 Dataset\n",
                "\n",
                "Downloading the CIFAR-100 dataset using torchvision. The dataset contains 60,000 32x32 color images in 100 classes."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "id": "i9j0k1l2",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Data will be saved to: /content/data\n"
                    ]
                }
            ],
            "source": [
                "# Define the data directory\n",
                "data_dir = './data'\n",
                "os.makedirs(data_dir, exist_ok=True)\n",
                "\n",
                "print(f\"Data will be saved to: {os.path.abspath(data_dir)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "id": "j0k1l2m3",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Downloading CIFAR-100 training set...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 169M/169M [00:03<00:00, 49.1MB/s] \n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Training set size: 50000 images\n",
                        "\n",
                        "Downloading CIFAR-100 test set...\n",
                        "Test set size: 10000 images\n"
                    ]
                }
            ],
            "source": [
                "# Download CIFAR-100 training set\n",
                "print(\"Downloading CIFAR-100 training set...\")\n",
                "cifar100_train = torchvision.datasets.CIFAR100(\n",
                "    root=data_dir,\n",
                "    train=True,\n",
                "    download=True\n",
                ")\n",
                "print(f\"Training set size: {len(cifar100_train)} images\")\n",
                "\n",
                "# Download CIFAR-100 test set\n",
                "print(\"\\nDownloading CIFAR-100 test set...\")\n",
                "cifar100_test = torchvision.datasets.CIFAR100(\n",
                "    root=data_dir,\n",
                "    train=False,\n",
                "    download=True\n",
                ")\n",
                "print(f\"Test set size: {len(cifar100_test)} images\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "id": "k1l2m3n4",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "==================================================\n",
                        "CIFAR-100 Dataset Information\n",
                        "==================================================\n",
                        "Number of classes: 100\n",
                        "Image size: 32x32x3\n",
                        "Training samples: 50000\n",
                        "Test samples: 10000\n",
                        "\n",
                        "Sample classes: ['apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle']...\n"
                    ]
                }
            ],
            "source": [
                "# Display dataset information\n",
                "print(\"\\n\" + \"=\"*50)\n",
                "print(\"CIFAR-100 Dataset Information\")\n",
                "print(\"=\"*50)\n",
                "print(f\"Number of classes: {len(cifar100_train.classes)}\")\n",
                "print(f\"Image size: 32x32x3\")\n",
                "print(f\"Training samples: {len(cifar100_train)}\")\n",
                "print(f\"Test samples: {len(cifar100_test)}\")\n",
                "print(f\"\\nSample classes: {cifar100_train.classes[:10]}...\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "summary_md",
            "metadata": {},
            "source": [
                "## 4. Summary\n",
                "\n",
                "Setup completed successfully!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "m3n4o5p6",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n\" + \"=\"*50)\n",
                "print(\"Setup Complete!\")\n",
                "print(\"=\"*50)\n",
                "print(\"\\nReady for next steps:\")\n",
                "print(\"- DINO model is available as 'dino_vits16'\")\n",
                "print(\"- CIFAR-100 data is saved in './data' directory\")\n",
                "print(\"- src imports are working\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
