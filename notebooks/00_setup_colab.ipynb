{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "a1b2c3d4",
            "metadata": {},
            "source": [
                "# Setup & Test - DINO + CIFAR-100\n",
                "\n",
                "This notebook:\n",
                "1. Tests the refactored `src` modules\n",
                "2. Loads **DINO ViT-S/16** using `src.model`\n",
                "\n",
                "3. Loads **CIFAR-100** using `src.data`4. Verifies everything works"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b2c3d4e5",
            "metadata": {},
            "source": [
                "## 1. Install Required Dependencies"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c3d4e5f6",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\u001b[31m\n",
                        "\u001b[0m"
                    ]
                }
            ],
            "source": [
                "# Install required packages (run if needed)\n",
                "#!pip install -q -r requirements.txt"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d4e5f6g7",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "PyTorch version: 2.9.0+cpu\n",
                        "Torchvision version: 0.24.0+cpu\n",
                        "CUDA available: False\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "import torch\n",
                "import torchvision\n",
                "\n",
                "from src.utils import set_seed, get_device, count_parameters\n",
                "\n",
                "from src.data import load_cifar100, create_dataloader, partition_iid, partition_non_iid\n",
                "\n",
                "from src.model import DINOClassifier, load_dino_backbone\n",
                "\n",
                "# Set seed for reproducibility\n",
                "\n",
                "print(f\"PyTorch version: {torch.__version__}\")\n",
                "\n",
                "print(f\"Torchvision version: {torchvision.__version__}\")\n",
                "\n",
                "device = get_device()\n",
                "\n",
                "print(f\"Device: {device}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e5f6g7h8",
            "metadata": {},
            "source": [
                "## 2. Download DINO ViT-S/16 Model\n",
                "\n",
                "Loading the pretrained DINO ViT-S/16 model from the official Facebook Research GitHub repository:\n",
                "https://github.com/facebookresearch/dino"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f6g7h8i9",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Downloading DINO ViT-S/16 model...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Using cache found in /root/.cache/torch/hub/facebookresearch_dino_main\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "DINO ViT-S/16 model loaded successfully!\n",
                        "Model architecture:\n",
                        "VisionTransformer(\n",
                        "  (patch_embed): PatchEmbed(\n",
                        "    (proj): Conv2d(3, 384, kernel_size=(16, 16), stride=(16, 16))\n",
                        "  )\n",
                        "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
                        "  (blocks): ModuleList(\n",
                        "    (0-11): 12 x Block(\n",
                        "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
                        "      (attn): Attention(\n",
                        "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
                        "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
                        "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
                        "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
                        "      )\n",
                        "      (drop_path): Identity()\n",
                        "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
                        "      (mlp): Mlp(\n",
                        "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
                        "        (act): GELU(approximate='none')\n",
                        "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
                        "        (drop): Dropout(p=0.0, inplace=False)\n",
                        "      )\n",
                        "    )\n",
                        "  )\n",
                        "  (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
                        "  (head): Identity()\n",
                        ")\n"
                    ]
                }
            ],
            "source": [
                "# Load DINO ViT-S/16 using refactored model.py\n",
                "print(\"Loading DINO ViT-S/16 model...\")\n",
                "\n",
                "model = DINOClassifier(model_name='dino_vits16', num_classes=100, device=device)\n",
                "model.eval()\n",
                "\n",
                "print(\"\\nDINO Classifier loaded successfully!\")\n",
                "print(f\"Backbone frozen: {model.freeze_backbone}\")\n",
                "print(f\"Output classes: 100\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "g7h8i9j0",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Total parameters: 21,665,664\n",
                        "Trainable parameters: 21,665,664\n"
                    ]
                }
            ],
            "source": [
                "# Model information using refactored utils\n",
                "total_params = count_parameters(model, trainable_only=False)\n",
                "trainable_params = count_parameters(model, trainable_only=True)\n",
                "\n",
                "print(f\"Total parameters: {total_params:,}\")\n",
                "print(f\"Trainable parameters: {trainable_params:,}\")\n",
                "print(f\"Trainable %: {100 * trainable_params / total_params:.2f}%\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "h8i9j0k1",
            "metadata": {},
            "source": [
                "## 3. Download CIFAR-100 Dataset\n",
                "\n",
                "Downloading the CIFAR-100 dataset using torchvision. The dataset contains 60,000 32x32 color images in 100 classes."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "i9j0k1l2",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Data will be saved to: /content/data\n"
                    ]
                }
            ],
            "source": [
                "# Define data directory\n",
                "data_dir = './data'\n",
                "print(f\"Data directory: {os.path.abspath(data_dir)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "j0k1l2m3",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Downloading CIFAR-100 training set...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 169M/169M [00:03<00:00, 49.1MB/s] \n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Training set size: 50000 images\n",
                        "\n",
                        "Downloading CIFAR-100 test set...\n",
                        "Test set size: 10000 images\n"
                    ]
                }
            ],
            "source": [
                "# Load CIFAR-100 using refactored data.py (with DINO transforms)\n",
                "print(\"Loading CIFAR-100 dataset...\")\n",
                "train_dataset, test_dataset = load_cifar100(data_dir=data_dir, image_size=224)\n",
                "\n",
                "print(f\"Training set: {len(train_dataset)} images\")\n",
                "print(f\"Test set: {len(test_dataset)} images\")\n",
                "print(f\"Image size after transform: 224x224 (DINO input size)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "k1l2m3n4",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "==================================================\n",
                        "CIFAR-100 Dataset Information\n",
                        "==================================================\n",
                        "Number of classes: 100\n",
                        "Image size: 32x32x3\n",
                        "Training samples: 50000\n",
                        "Test samples: 10000\n",
                        "\n",
                        "Sample classes: ['apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle']...\n"
                    ]
                }
            ],
            "source": [
                "# Display dataset information\n",
                "print(\"\\n\" + \"=\"*50)\n",
                "print(\"CIFAR-100 Dataset Information\")\n",
                "print(\"=\"*50)\n",
                "print(f\"Number of classes: {len(train_dataset.classes)}\")\n",
                "print(f\"Original size: 32x32x3\")\n",
                "print(f\"Transformed size: 224x224x3 (for DINO)\")\n",
                "print(f\"Training samples: {len(train_dataset)}\")\n",
                "print(f\"Test samples: {len(test_dataset)}\")\n",
                "print(f\"\\nSample classes: {train_dataset.classes[:10]}...\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "summary_md",
            "metadata": {},
            "source": [
                "## 4. Test Forward Pass"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "33e11e35",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test model with a batch\n",
                "test_loader = create_dataloader(test_dataset, batch_size=8, shuffle=False, num_workers=0)\n",
                "images, labels = next(iter(test_loader))\n",
                "\n",
                "print(f\"Batch shape: {images.shape}\")\n",
                "print(f\"Labels: {labels}\")\n",
                "\n",
                "# Forward pass\n",
                "model.to(device)\n",
                "images = images.to(device)\n",
                "with torch.no_grad():\n",
                "    outputs = model(images)\n",
                "\n",
                "print(f\"\\nOutput shape: {outputs.shape}\")\n",
                "print(f\"Output range: [{outputs.min():.2f}, {outputs.max():.2f}]\")\n",
                "print(\"\\n✓ Forward pass successful!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d46376bc",
            "metadata": {},
            "source": [
                "## 5. Test FL Partitioning (M1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "12e37b8a",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test IID partitioning\n",
                "print(\"Testing IID partitioning...\")\n",
                "num_clients = 10\n",
                "client_datasets_iid = partition_iid(train_dataset, num_clients=num_clients, seed=42)\n",
                "\n",
                "print(f\"Number of clients: {num_clients}\")\n",
                "for i in range(min(3, num_clients)):\n",
                "    print(f\"Client {i}: {len(client_datasets_iid[i])} samples\")\n",
                "\n",
                "# Test non-IID partitioning\n",
                "print(\"\\nTesting non-IID partitioning...\")\n",
                "num_classes_per_client = 10\n",
                "client_datasets_noniid = partition_non_iid(\n",
                "    train_dataset, \n",
                "    num_clients=num_clients, \n",
                "    num_classes_per_client=num_classes_per_client,\n",
                "    seed=42\n",
                ")\n",
                "\n",
                "for i in range(min(3, num_clients)):\n",
                "    # Get labels for this client\n",
                "    subset = client_datasets_noniid[i]\n",
                "    client_labels = [train_dataset.targets[idx] for idx in subset.indices]\n",
                "    unique_classes = len(set(client_labels))\n",
                "    print(f\"Client {i}: {len(subset)} samples, {unique_classes} unique classes\")\n",
                "\n",
                "print(\"\\n✓ FL partitioning works!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "14545283",
            "metadata": {},
            "source": [
                "## 6. Summary\n",
                "\n",
                "Setup completed successfully!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "m3n4o5p6",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n\" + \"=\"*50)\n",
                "print(\"Setup Complete!\")\n",
                "print(\"=\"*50)\n",
                "print(\"\\n✓ All refactored modules working:\")\n",
                "print(\"  - src.utils: set_seed, get_device, count_parameters\")\n",
                "print(\"  - src.data: load_cifar100, create_dataloader, partitioning\")\n",
                "print(\"  - src.model: DINOClassifier\")\n",
                "\n",
                "print(\"\\n✓ DINO model loaded and tested\")print(\"\\nReady for M3 (Central Baseline) and M4 (FedAvg)!\")\n",
                "\n",
                "print(\"✓ CIFAR-100 data loaded with transforms\")print(\"✓ FL partitioning (IID/non-IID) verified\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
