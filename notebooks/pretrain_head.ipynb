{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "header",
            "metadata": {},
            "source": [
                "# AML Project 2: Protocol Step 1 - Pre-train Linear Head\n",
                "\n",
                "This notebook implements the first step of the experimental protocol:\n",
                "- **Goal:** Train a linear classifier on top of the frozen DINO backbone.\n",
                "- **Backbone:** Frozen (`freeze_policy='head_only'`)\n",
                "- **Classifier:** Unfrozen (`freeze_head=False`)\n",
                "- **Epochs:** 20\n",
                "- **Output:** `output/main/pretrained_head.pt`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "setup",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Clone Repository & Install Dependencies\n",
                "!git clone https://github.com/emanueleR3/AML-Project-2.git\n",
                "%cd AML-Project-2\n",
                "!pip install -r requirements.txt\n",
                "!pip install torch torchvision numpy matplotlib tqdm"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "imports",
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import os\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "\n",
                "from src.utils import set_seed, get_device, ensure_dir, save_checkpoint, save_metrics_json, count_parameters\n",
                "from src.data import load_cifar100, create_dataloader\n",
                "from src.model import build_model\n",
                "from src.train import evaluate, train_one_epoch\n",
                "\n",
                "sys.path.append('.')\n",
                "\n",
                "OUTPUT_DIR = 'output/main'\n",
                "ensure_dir(OUTPUT_DIR)\n",
                "device = get_device()\n",
                "set_seed(42)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "load_data",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Loading CIFAR-100...\")\n",
                "train_trainval, test_dataset = load_cifar100(data_dir='./data', image_size=224, download=True)\n",
                "\n",
                "train_size = int(0.9 * len(train_trainval))\n",
                "val_size = len(train_trainval) - train_size\n",
                "train_dataset, val_dataset = torch.utils.data.random_split(\n",
                "    train_trainval, [train_size, val_size], generator=torch.Generator().manual_seed(42)\n",
                ")\n",
                "\n",
                "train_loader = create_dataloader(train_dataset, batch_size=64, shuffle=True)\n",
                "val_loader = create_dataloader(val_dataset, batch_size=64, shuffle=False)\n",
                "test_loader = create_dataloader(test_dataset, batch_size=64, shuffle=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "model_config",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Configuration for Head Pre-training\n",
                "config = {\n",
                "    'model_name': 'dino_vits16',\n",
                "    'num_classes': 100,\n",
                "    'freeze_policy': 'head_only',  # Freeze backbone\n",
                "    'freeze_head': False,         # Train head\n",
                "    'dropout': 0.1,\n",
                "    'device': device\n",
                "}\n",
                "\n",
                "model = build_model(config)\n",
                "model.to(device)\n",
                "\n",
                "print(f\"Total parameters: {count_parameters(model):,}\")\n",
                "print(f\"Trainable parameters: {count_parameters(model, trainable_only=True):,}\")\n",
                "# Expect ~38k trainable params (384*100 + bias)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "train",
            "metadata": {},
            "outputs": [],
            "source": [
                "epochs = 20\n",
                "optimizer = torch.optim.SGD(model.get_trainable_params(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
                "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
                "criterion = nn.CrossEntropyLoss()\n",
                "\n",
                "best_acc = 0.0\n",
                "history = {'train_loss': [], 'val_acc': []}\n",
                "\n",
                "print(f\"Starting Head Pre-training for {epochs} epochs...\")\n",
                "\n",
                "for epoch in range(epochs):\n",
                "    loss, acc = train_one_epoch(model, train_loader, optimizer, criterion, device, show_progress=False)\n",
                "    \n",
                "    # Validation\n",
                "    val_loss, val_acc = evaluate(model, val_loader, criterion, device, show_progress=False)\n",
                "        \n",
                "    if val_acc > best_acc:\n",
                "        best_acc = val_acc\n",
                "        # Save as PRETRAINED HEAD\n",
                "        save_checkpoint({'model_state_dict': model.state_dict()}, os.path.join(OUTPUT_DIR, 'pretrained_head.pt'))\n",
                "            \n",
                "    print(f\"Epoch {epoch+1}/{epochs} | Train Acc: {acc:.2f}% | Val Acc: {val_acc:.2f}% | Best: {best_acc:.2f}%\")\n",
                "    \n",
                "    scheduler.step()\n",
                "    history['train_loss'].append(loss)\n",
                "    history['val_acc'].append(val_acc)\n",
                "\n",
                "print(f\"Pre-training finished. Best Val Acc: {best_acc:.2f}%\")\n",
                "save_metrics_json(os.path.join(OUTPUT_DIR, 'pretrained_head_metrics.json'), history)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}