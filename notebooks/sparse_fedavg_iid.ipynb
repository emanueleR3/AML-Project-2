{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "header",
            "metadata": {},
            "source": [
                "# Sparse FedAvg IID (Comparison)\n",
                "\n",
                "This notebook runs the **Sparse** FedAvg IID experiment to compare against the Dense IID Baseline.\n",
                "- **Sparsity:** 50% (from ablation study)\n",
                "- **Calibration Rounds:** 3 (from ablation study)\n",
                "- **Training Rounds:** 200"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "setup",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Clone Repository & Install Dependencies\n",
                "!git clone https://github.com/emanueleR3/AML-Project-2.git\n",
                "%cd AML-Project-2\n",
                "!pip install -r requirements.txt\n",
                "!pip install torch torchvision numpy matplotlib tqdm"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "imports",
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import os\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import numpy as np\n",
                "\n",
                "from src.utils import set_seed, get_device, ensure_dir, save_metrics_json, save_checkpoint\n",
                "from src.data import load_cifar100, create_dataloader, partition_iid\n",
                "from src.model import build_model\n",
                "from src.train import evaluate\n",
                "from src.sparse_fedavg import run_fedavg_sparse_round\n",
                "from src.masking import compute_fisher_diagonal, create_mask, get_mask_sparsity\n",
                "\n",
                "sys.path.append('.')\n",
                "\n",
                "OUTPUT_DIR = 'output/comparison'\n",
                "ensure_dir(OUTPUT_DIR)\n",
                "device = get_device()\n",
                "set_seed(42)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "config",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load Data\n",
                "train_full, test_data = load_cifar100(data_dir='./data', download=True)\n",
                "train_size = int(0.9 * len(train_full))\n",
                "val_size = len(train_full) - train_size\n",
                "train_data, val_data = torch.utils.data.random_split(\n",
                "    train_full, [train_size, val_size], generator=torch.Generator().manual_seed(42)\n",
                ")\n",
                "\n",
                "val_loader = create_dataloader(val_data, batch_size=64, shuffle=False)\n",
                "test_loader = create_dataloader(test_data, batch_size=64, shuffle=False)\n",
                "\n",
                "# Configuration (matching dense baseline)\n",
                "NUM_ROUNDS = 200\n",
                "NUM_CLIENTS = 100\n",
                "CLIENTS_PER_ROUND = 0.1\n",
                "LOCAL_STEPS = 4\n",
                "LR = 1e-4\n",
                "WEIGHT_DECAY = 1e-4\n",
                "EVAL_FREQ = 10\n",
                "\n",
                "# Optimal values from ablation study\n",
                "SPARSITY = 0.5       \n",
                "CALIB_ROUNDS = 3    \n",
                "\n",
                "model_config = {\n",
                "    'model_name': 'dino_vits16',\n",
                "    'num_classes': 100,\n",
                "    'freeze_policy': 'finetune_all',\n",
                "    'freeze_head': True,\n",
                "    'device': device\n",
                "}\n",
                "\n",
                "BASELINE_PATH = 'output/main/pretrained_head.pt'\n",
                "\n",
                "print(f\"Train: {len(train_data)}, Val: {len(val_data)}, Test: {len(test_data)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "mask_logic",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Partition Data (IID)\n",
                "client_datasets = partition_iid(train_data, NUM_CLIENTS)\n",
                "client_loaders = [create_dataloader(ds, 32, True, 0) for ds in client_datasets]\n",
                "print(f\"Created {NUM_CLIENTS} IID client loaders\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "run_training",
            "metadata": {},
            "outputs": [],
            "source": [
                "model = build_model(model_config)\n",
                "model.to(device)\n",
                "checkpoint = torch.load(BASELINE_PATH, map_location=device)\n",
                "model.load_state_dict(checkpoint['model_state_dict'])\n",
                "print(f\"Loaded pretrained head from {BASELINE_PATH}\")\n",
                "\n",
                "\n",
                "print(f\"\\n=== Fisher Calibration ({CALIB_ROUNDS} rounds) ===\")\n",
                "\n",
                "calib_clients_per_round = max(1, int(NUM_CLIENTS * CLIENTS_PER_ROUND))\n",
                "\n",
                "aggregated_fisher = None\n",
                "for calib_round in range(CALIB_ROUNDS):\n",
                "    selected_clients = np.random.choice(NUM_CLIENTS, calib_clients_per_round, replace=False)\n",
                "    \n",
                "    round_fisher = None\n",
                "    for client_idx in selected_clients:\n",
                "        client_loader = client_loaders[client_idx]\n",
                "        fisher = compute_fisher_diagonal(model, client_loader, device, num_batches=5)\n",
                "        \n",
                "        if round_fisher is None:\n",
                "            round_fisher = {k: v.clone() for k, v in fisher.items()}\n",
                "        else:\n",
                "            for k in round_fisher:\n",
                "                round_fisher[k] += fisher[k]\n",
                "    \n",
                "    for k in round_fisher:\n",
                "        round_fisher[k] /= len(selected_clients)\n",
                "    \n",
                "    if aggregated_fisher is None:\n",
                "        aggregated_fisher = {k: v.clone() for k, v in round_fisher.items()}\n",
                "    else:\n",
                "        for k in aggregated_fisher:\n",
                "            aggregated_fisher[k] += round_fisher[k]\n",
                "    \n",
                "    print(f\"  Calibration round {calib_round + 1}/{CALIB_ROUNDS} complete\")\n",
                "\n",
                "for k in aggregated_fisher:\n",
                "    aggregated_fisher[k] /= CALIB_ROUNDS\n",
                "\n",
                "# Create mask using LEAST SENSITIVE parameters\n",
                "mask = create_mask(aggregated_fisher, model, sparsity_ratio=SPARSITY, rule='least_sensitive')\n",
                "actual_sparsity = get_mask_sparsity(mask)\n",
                "print(f\"Created mask with {actual_sparsity*100:.1f}% sparsity (rule: least_sensitive)\")\n",
                "\n",
                "# Save mask\n",
                "MASK_OUTPUT = os.path.join(OUTPUT_DIR, 'mask_iid_ls.pt')\n",
                "torch.save(mask, MASK_OUTPUT)\n",
                "print(f\"Saved mask to {MASK_OUTPUT}\")\n",
                "\n",
                "\n",
                "print(f\"\\n=== Sparse IID Training ({NUM_ROUNDS} rounds) ===\")\n",
                "\n",
                "history = {'round': [], 'train_acc': [], 'val_acc': [], 'test_acc': []}\n",
                "best_val_acc = 0.0\n",
                "criterion = nn.CrossEntropyLoss()\n",
                "\n",
                "for round_idx in range(NUM_ROUNDS):\n",
                "    num_selected = max(1, int(NUM_CLIENTS * CLIENTS_PER_ROUND))\n",
                "    selected_clients = np.random.choice(NUM_CLIENTS, num_selected, replace=False)\n",
                "    \n",
                "    loss, train_acc = run_fedavg_sparse_round(\n",
                "        model, client_loaders, selected_clients.tolist(),\n",
                "        lr=LR, weight_decay=WEIGHT_DECAY, device=device,\n",
                "        local_steps=LOCAL_STEPS, mask=mask\n",
                "    )\n",
                "    \n",
                "    history['round'].append(round_idx + 1)\n",
                "    history['train_acc'].append(train_acc)\n",
                "    \n",
                "    if (round_idx + 1) % EVAL_FREQ == 0 or round_idx == NUM_ROUNDS - 1:\n",
                "        val_loss, val_acc = evaluate(model, val_loader, criterion, device, show_progress=False)\n",
                "        test_loss, test_acc = evaluate(model, test_loader, criterion, device, show_progress=False)\n",
                "        history['val_acc'].append(val_acc)\n",
                "        history['test_acc'].append(test_acc)\n",
                "        \n",
                "        print(f\"Round {round_idx + 1}/{NUM_ROUNDS}: Train={train_acc:.2f}%, Val={val_acc:.2f}%, Test={test_acc:.2f}%\")\n",
                "        \n",
                "        if val_acc > best_val_acc:\n",
                "            best_val_acc = val_acc\n",
                "            save_checkpoint({'model_state_dict': model.state_dict()}, \n",
                "                          os.path.join(OUTPUT_DIR, 'sparse_iid_best.pt'))\n",
                "    else:\n",
                "        history['val_acc'].append(None)\n",
                "        history['test_acc'].append(None)\n",
                "\n",
                "save_metrics_json(os.path.join(OUTPUT_DIR, 'sparse_iid_metrics.json'), history)\n",
                "print(f\"\\n=== Done! Best Val Acc: {best_val_acc:.2f}% ===\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
