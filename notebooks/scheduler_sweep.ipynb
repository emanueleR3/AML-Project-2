{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "header",
            "metadata": {},
            "source": [
                "# Learning Rate Scheduler Sweep (Central Baseline)\n",
                "\n",
                "This notebook compares different LR schedulers to optimize the **Central Baseline**.\n",
                "\n",
                "**Configuration:**\n",
                "- **Model:** DINO ViT-S/16\n",
                "- **Strategy:** Fine-tune backbone (`finetune_all`), Frozen Head\n",
                "- **Optimizer:** SGDM (lr=1e-5, momentum=0.9, wd=1e-4)\n",
                "- **Epochs:** 16 (Less than the actual baseline for faster testing)\n",
                "\n",
                "**Schedulers tested:**\n",
                "1. Cosine Annealing\n",
                "2. Step LR\n",
                "3. Exponential LR\n",
                "4. ReduceOnPlateau"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "setup",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Clone Repository & Install Dependencies\n",
                "!git clone https://github.com/emanueleR3/AML-Project-2.git\n",
                "%cd AML-Project-2\n",
                "!pip install -q -r requirements.txt\n",
                "!pip install torch torchvision numpy matplotlib tqdm pandas"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "imports",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import sys\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "from torch.optim.lr_scheduler import (\n",
                "    CosineAnnealingLR,\n",
                "    StepLR,\n",
                "    ExponentialLR,\n",
                "    ReduceLROnPlateau\n",
                ")\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import pandas as pd\n",
                "\n",
                "from src.utils import set_seed, get_device, ensure_dir, save_metrics_json\n",
                "from src.data import load_cifar100, create_dataloader\n",
                "from src.model import build_model\n",
                "from src.train import train_one_epoch, evaluate\n",
                "\n",
                "sys.path.append('.')\n",
                "\n",
                "OUTPUT_DIR = 'output/scheduler_sweep'\n",
                "ensure_dir(OUTPUT_DIR)\n",
                "device = get_device()\n",
                "set_seed(42)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "load_data",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load CIFAR-100\n",
                "train_full, test_data = load_cifar100(data_dir='./data', download=True)\n",
                "\n",
                "train_size = int(0.9 * len(train_full))\n",
                "val_size = len(train_full) - train_size\n",
                "train_data, val_data = torch.utils.data.random_split(\n",
                "    train_full, [train_size, val_size],\n",
                "    generator=torch.Generator().manual_seed(42)\n",
                ")\n",
                "\n",
                "train_loader = create_dataloader(train_data, batch_size=64, shuffle=True)\n",
                "val_loader = create_dataloader(val_data, batch_size=64, shuffle=False)\n",
                "test_loader = create_dataloader(test_data, batch_size=64, shuffle=False)\n",
                "\n",
                "print(f\"Train: {len(train_data)}, Val: {len(val_data)}, Test: {len(test_data)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "config",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Model config\n",
                "config = {\n",
                "    'model_name': 'dino_vits16',\n",
                "    'num_classes': 100,\n",
                "    'freeze_policy': 'finetune_all',\n",
                "    'freeze_head': True,\n",
                "    'dropout': 0.1,\n",
                "    'device': device\n",
                "}\n",
                "\n",
                "\n",
                "NUM_EPOCHS = 16        \n",
                "BASE_LR = 1e-5\n",
                "WEIGHT_DECAY = 1e-4\n",
                "MOMENTUM = 0.9\n",
                "EVAL_FREQ = 2\n",
                "\n",
                "# Check for pretrained head\n",
                "BASELINE_PATH = 'output/main/pretrained_head.pt'\n",
                "if not os.path.exists(BASELINE_PATH):\n",
                "    print(\"âš  CAUTION: output/main/pretrained_head.pt not found. Results may be suboptimal.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "scheduler_logic",
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_scheduler(name, optimizer, num_epochs):\n",
                "    \"\"\"Factory for schedulers with dynamic sizing.\"\"\"\n",
                "    if name == 'cosine':\n",
                "        return CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
                "    elif name == 'step':\n",
                "        step_size = max(1, num_epochs // 3)\n",
                "        return StepLR(optimizer, step_size=step_size, gamma=0.1)\n",
                "    elif name == 'exponential':\n",
                "        return ExponentialLR(optimizer, gamma=0.9)\n",
                "    elif name == 'plateau':\n",
                "        return ReduceLROnPlateau(optimizer, mode='max', patience=3, factor=0.5)\n",
                "    else:\n",
                "        raise ValueError(f\"Unknown scheduler: {name}\")\n",
                "\n",
                "\n",
                "def train_with_scheduler(scheduler_name):\n",
                "    print(f\"\\n{'='*40}\")\n",
                "    print(f\"Training with: {scheduler_name.upper()}\")\n",
                "    print(f\"{'='*40}\")\n",
                "    \n",
                "    # 1. Build Model\n",
                "    model = build_model(config)\n",
                "    model.to(device)\n",
                "    \n",
                "    # Load Pretrained Head\n",
                "    if os.path.exists(BASELINE_PATH):\n",
                "        ckpt = torch.load(BASELINE_PATH, map_location=device)\n",
                "        model.load_state_dict(ckpt['model_state_dict'])\n",
                "    \n",
                "    # Helper to count trainable parameters\n",
                "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
                "    \n",
                "    # 3. Setup Optimizer\n",
                "    optimizer = optim.SGD(\n",
                "        model.get_trainable_params(), \n",
                "        lr=BASE_LR, \n",
                "        momentum=MOMENTUM, \n",
                "        weight_decay=WEIGHT_DECAY\n",
                "    )\n",
                "    scheduler = get_scheduler(scheduler_name, optimizer, NUM_EPOCHS)\n",
                "    criterion = nn.CrossEntropyLoss()\n",
                "    \n",
                "    # 4. Training Loop\n",
                "    history = {\n",
                "        'epoch': [], \n",
                "        'train_loss': [], 'train_acc': [],\n",
                "        'val_loss': [], 'val_acc': [], \n",
                "        'test_loss': [], 'test_acc': [],\n",
                "        'lr': []\n",
                "    }\n",
                "    \n",
                "    best_val_acc = 0.0\n",
                "    \n",
                "    for epoch in range(1, NUM_EPOCHS + 1):\n",
                "        loss, acc = train_one_epoch(\n",
                "            model, train_loader, optimizer, criterion, device, show_progress=False\n",
                "        )\n",
                "        current_lr = optimizer.param_groups[0]['lr']\n",
                "        \n",
                "        # Eval\n",
                "        if epoch % EVAL_FREQ == 0 or epoch == NUM_EPOCHS:\n",
                "            val_loss, val_acc = evaluate(model, val_loader, criterion, device, show_progress=False)\n",
                "            test_loss, test_acc = evaluate(model, test_loader, criterion, device, show_progress=False)\n",
                "            \n",
                "            if val_acc > best_val_acc:\n",
                "                best_val_acc = val_acc\n",
                "            \n",
                "            print(f\"Epoch {epoch}/{NUM_EPOCHS} | LR: {current_lr:.2e} | Train: {acc:.1f}% | Val: {val_acc:.1f}% | Test: {test_acc:.1f}%\")\n",
                "            \n",
                "            history['val_loss'].append(val_loss)\n",
                "            history['val_acc'].append(val_acc)\n",
                "            history['test_loss'].append(test_loss)\n",
                "            history['test_acc'].append(test_acc)\n",
                "        else:\n",
                "            history['val_loss'].append(None)\n",
                "            history['val_acc'].append(None)\n",
                "            history['test_loss'].append(None)\n",
                "            history['test_acc'].append(None)\n",
                "            print(f\"Epoch {epoch}/{NUM_EPOCHS} | LR: {current_lr:.2e} | Train: {acc:.1f}%\")\n",
                "        \n",
                "        history['epoch'].append(epoch)\n",
                "        history['train_loss'].append(loss)\n",
                "        history['train_acc'].append(acc)\n",
                "        history['lr'].append(current_lr)\n",
                "        \n",
                "        # Step Scheduler\n",
                "        if scheduler is not None:\n",
                "            if scheduler_name == 'plateau':\n",
                "                metric = history['val_acc'][-1] if history['val_acc'][-1] is not None else 0\n",
                "                scheduler.step(metric)\n",
                "            else:\n",
                "                scheduler.step()\n",
                "                \n",
                "    # Capture final stats\n",
                "    history['best_val_acc'] = best_val_acc\n",
                "    valid_test = [x for x in history['test_acc'] if x is not None]\n",
                "    history['final_test_acc'] = valid_test[-1] if valid_test else 0.0\n",
                "    \n",
                "    return history"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "run_sweep",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run all Schedulers\n",
                "SCHEDULERS = ['cosine', 'step', 'exponential', 'plateau']\n",
                "results = {}\n",
                "\n",
                "for name in SCHEDULERS:\n",
                "    results[name] = train_with_scheduler(name)\n",
                "    save_metrics_json(os.path.join(OUTPUT_DIR, f'scheduler_{name}.json'), results[name])"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
