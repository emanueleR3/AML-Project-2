{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "header",
            "metadata": {},
            "source": [
                "# Learning Rate Scheduler Sweep\n",
                "\n",
                "This notebook compares different LR schedulers on the central baseline to find the optimal one.\n",
                "\n",
                "**Schedulers tested:**\n",
                "1. Cosine Annealing (current default)\n",
                "2. Step LR (decay every N epochs)\n",
                "3. Exponential LR\n",
                "4. ReduceOnPlateau\n",
                "5. Constant LR (no scheduling)\n",
                "\n",
                "**Estimated runtime: ~1 hour on T4 GPU** (5 schedulers × 20 epochs, eval every 2)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "setup",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import sys\n",
                "\n",
                "if not os.path.exists('AML-Project-2') and not os.path.exists('src'):\n",
                "    !git clone https://github.com/emanueleR3/AML-Project-2.git\n",
                "    %cd AML-Project-2\n",
                "\n",
                "!pip install -q -r requirements.txt"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "imports",
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "from torch.optim.lr_scheduler import (\n",
                "    CosineAnnealingLR,\n",
                "    StepLR,\n",
                "    ExponentialLR,\n",
                "    ReduceLROnPlateau,\n",
                "    CosineAnnealingWarmRestarts\n",
                ")\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import pandas as pd\n",
                "\n",
                "from src.utils import set_seed, get_device, ensure_dir, save_metrics_json\n",
                "from src.data import load_cifar100, create_dataloader\n",
                "from src.model import build_model\n",
                "from src.train import train_one_epoch, evaluate\n",
                "\n",
                "OUTPUT_DIR = 'output/scheduler_sweep'\n",
                "ensure_dir(OUTPUT_DIR)\n",
                "device = get_device()\n",
                "print(f\"Device: {device}\")\n",
                "\n",
                "set_seed(42)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "load_data",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load CIFAR-100\n",
                "train_full, test_data = load_cifar100(data_dir='./data', download=True)\n",
                "\n",
                "train_size = int(0.9 * len(train_full))\n",
                "val_size = len(train_full) - train_size\n",
                "train_data, val_data = torch.utils.data.random_split(\n",
                "    train_full, [train_size, val_size],\n",
                "    generator=torch.Generator().manual_seed(42)\n",
                ")\n",
                "\n",
                "train_loader = create_dataloader(train_data, batch_size=64, shuffle=True)\n",
                "val_loader = create_dataloader(val_data, batch_size=64, shuffle=False)\n",
                "test_loader = create_dataloader(test_data, batch_size=64, shuffle=False)\n",
                "\n",
                "print(f\"Train: {len(train_data)}, Val: {len(val_data)}, Test: {len(test_data)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "config",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Model config\n",
                "config = {\n",
                "    'model_name': 'dino_vits16',\n",
                "    'num_classes': 100,\n",
                "    'freeze_policy': 'head_only',\n",
                "    'dropout': 0.1,\n",
                "    'device': device,\n",
                "    'seed': 42\n",
                "}\n",
                "\n",
                "# Training config\n",
                "NUM_EPOCHS = 20\n",
                "BASE_LR = 0.001\n",
                "WEIGHT_DECAY = 1e-4\n",
                "EVAL_FREQ = 2  # Evaluate every 2 epochs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "scheduler_factory",
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_scheduler(name, optimizer, num_epochs):\n",
                "    \"\"\"Factory function to create schedulers by name.\"\"\"\n",
                "    schedulers = {\n",
                "        'cosine': lambda: CosineAnnealingLR(optimizer, T_max=num_epochs),\n",
                "        'step': lambda: StepLR(optimizer, step_size=5, gamma=0.5),\n",
                "        'exponential': lambda: ExponentialLR(optimizer, gamma=0.9),\n",
                "        'plateau': lambda: ReduceLROnPlateau(optimizer, mode='max', patience=3, factor=0.5),\n",
                "        'constant': lambda: None,\n",
                "        'warmup_cosine': lambda: CosineAnnealingWarmRestarts(optimizer, T_0=5, T_mult=2),\n",
                "    }\n",
                "    return schedulers.get(name, lambda: None)()\n",
                "\n",
                "\n",
                "def train_with_scheduler(scheduler_name, num_epochs=NUM_EPOCHS, eval_freq=EVAL_FREQ):\n",
                "    \"\"\"Train central baseline with specified scheduler.\"\"\"\n",
                "    print(f\"\\nTraining with: {scheduler_name}\")\n",
                "    print(\"-\" * 40)\n",
                "    \n",
                "    model = build_model(config)\n",
                "    model.to(device)\n",
                "    \n",
                "    optimizer = optim.AdamW(model.parameters(), lr=BASE_LR, weight_decay=WEIGHT_DECAY)\n",
                "    scheduler = get_scheduler(scheduler_name, optimizer, num_epochs)\n",
                "    criterion = nn.CrossEntropyLoss()\n",
                "    \n",
                "    history = {\n",
                "        'epoch': [], 'train_loss': [], 'train_acc': [],\n",
                "        'val_acc': [], 'test_acc': [], 'lr': []\n",
                "    }\n",
                "    \n",
                "    best_val_acc = 0\n",
                "    last_val_acc = 0\n",
                "    last_test_acc = 0\n",
                "    \n",
                "    for epoch in range(1, num_epochs + 1):\n",
                "        current_lr = optimizer.param_groups[0]['lr']\n",
                "        \n",
                "        # Train - NOTE: order is (model, loader, optimizer, criterion, device)\n",
                "        train_loss, train_acc = train_one_epoch(\n",
                "            model, train_loader, optimizer, criterion, device, show_progress=False\n",
                "        )\n",
                "        \n",
                "        # Evaluate every eval_freq epochs or at the end\n",
                "        if epoch % eval_freq == 0 or epoch == num_epochs:\n",
                "            _, val_acc = evaluate(model, val_loader, criterion, device, show_progress=False)\n",
                "            _, test_acc = evaluate(model, test_loader, criterion, device, show_progress=False)\n",
                "            last_val_acc = val_acc\n",
                "            last_test_acc = test_acc\n",
                "            \n",
                "            if val_acc > best_val_acc:\n",
                "                best_val_acc = val_acc\n",
                "            \n",
                "            print(f\"Epoch {epoch:2d} | LR: {current_lr:.6f} | Train: {train_acc:.1f}% | Val: {val_acc:.1f}% | Test: {test_acc:.1f}%\")\n",
                "        else:\n",
                "            val_acc = float('nan')\n",
                "            test_acc = float('nan')\n",
                "            print(f\"Epoch {epoch:2d} | LR: {current_lr:.6f} | Train: {train_acc:.1f}%\")\n",
                "        \n",
                "        # Update scheduler\n",
                "        if scheduler is not None:\n",
                "            if scheduler_name == 'plateau':\n",
                "                scheduler.step(last_val_acc)\n",
                "            else:\n",
                "                scheduler.step()\n",
                "        \n",
                "        history['epoch'].append(epoch)\n",
                "        history['train_loss'].append(train_loss)\n",
                "        history['train_acc'].append(train_acc)\n",
                "        history['val_acc'].append(val_acc)\n",
                "        history['test_acc'].append(test_acc)\n",
                "        history['lr'].append(current_lr)\n",
                "    \n",
                "    history['best_val_acc'] = best_val_acc\n",
                "    history['final_test_acc'] = last_test_acc\n",
                "    \n",
                "    return history"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "sweep_header",
            "metadata": {},
            "source": [
                "## Run Scheduler Sweep"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "run_sweep",
            "metadata": {},
            "outputs": [],
            "source": [
                "SCHEDULERS = ['cosine', 'step', 'exponential', 'plateau', 'constant']\n",
                "\n",
                "results = {}\n",
                "\n",
                "for sched_name in SCHEDULERS:\n",
                "    print(f\"\\n{'='*50}\")\n",
                "    print(f\"Scheduler: {sched_name.upper()}\")\n",
                "    print(f\"{'='*50}\")\n",
                "    \n",
                "    history = train_with_scheduler(sched_name)\n",
                "    results[sched_name] = history\n",
                "    \n",
                "    save_metrics_json(os.path.join(OUTPUT_DIR, f'scheduler_{sched_name}.json'), history)\n",
                "    \n",
                "    print(f\"\\n→ Best Val: {history['best_val_acc']:.2f}% | Final Test: {history['final_test_acc']:.2f}%\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "results_header",
            "metadata": {},
            "source": [
                "## Results Summary"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "summary",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"SCHEDULER COMPARISON RESULTS\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "summary_data = []\n",
                "for name, hist in results.items():\n",
                "    summary_data.append({\n",
                "        'Scheduler': name.upper(),\n",
                "        'Best Val Acc (%)': hist['best_val_acc'],\n",
                "        'Final Test Acc (%)': hist['final_test_acc'],\n",
                "    })\n",
                "\n",
                "df = pd.DataFrame(summary_data).sort_values('Best Val Acc (%)', ascending=False)\n",
                "print(df.to_string(index=False))\n",
                "\n",
                "best = df.iloc[0]\n",
                "print(f\"\\n★ BEST SCHEDULER: {best['Scheduler']} ({best['Best Val Acc (%)']:.2f}% val, {best['Final Test Acc (%)']:.2f}% test)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "visualization",
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
                "\n",
                "colors = {'cosine': '#2ecc71', 'step': '#3498db', 'exponential': '#e74c3c', \n",
                "          'plateau': '#9b59b6', 'constant': '#95a5a6'}\n",
                "\n",
                "# Plot 1: Validation Accuracy (filter out NaN)\n",
                "ax1 = axes[0]\n",
                "for name, hist in results.items():\n",
                "    epochs = np.array(hist['epoch'])\n",
                "    val_acc = np.array(hist['val_acc'])\n",
                "    valid = ~np.isnan(val_acc)\n",
                "    ax1.plot(epochs[valid], val_acc[valid], 'o-', label=name, color=colors.get(name, 'gray'), linewidth=2)\n",
                "ax1.set_xlabel('Epoch')\n",
                "ax1.set_ylabel('Validation Accuracy (%)')\n",
                "ax1.set_title('Validation Accuracy by Scheduler')\n",
                "ax1.legend()\n",
                "ax1.grid(alpha=0.3)\n",
                "\n",
                "# Plot 2: Learning Rate Schedule\n",
                "ax2 = axes[1]\n",
                "for name, hist in results.items():\n",
                "    ax2.plot(hist['epoch'], hist['lr'], label=name, color=colors.get(name, 'gray'), linewidth=2)\n",
                "ax2.set_xlabel('Epoch')\n",
                "ax2.set_ylabel('Learning Rate')\n",
                "ax2.set_title('Learning Rate Schedule')\n",
                "ax2.legend()\n",
                "ax2.grid(alpha=0.3)\n",
                "ax2.set_yscale('log')\n",
                "\n",
                "# Plot 3: Final Comparison Bar\n",
                "ax3 = axes[2]\n",
                "names = list(results.keys())\n",
                "test_accs = [results[n]['final_test_acc'] for n in names]\n",
                "bars = ax3.bar(names, test_accs, color=[colors.get(n, 'gray') for n in names])\n",
                "ax3.set_ylabel('Test Accuracy (%)')\n",
                "ax3.set_title('Final Test Accuracy')\n",
                "ax3.grid(axis='y', alpha=0.3)\n",
                "for bar, acc in zip(bars, test_accs):\n",
                "    ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.3, f'{acc:.1f}', ha='center', fontsize=10)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig(os.path.join(OUTPUT_DIR, 'scheduler_comparison.pdf'), bbox_inches='tight')\n",
                "plt.savefig(os.path.join(OUTPUT_DIR, 'scheduler_comparison.png'), dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "save_summary",
            "metadata": {},
            "outputs": [],
            "source": [
                "summary = {\n",
                "    'best_scheduler': df.iloc[0]['Scheduler'].lower(),\n",
                "    'best_val_acc': df.iloc[0]['Best Val Acc (%)'],\n",
                "    'best_test_acc': df.iloc[0]['Final Test Acc (%)'],\n",
                "    'all_results': {name: {'val': h['best_val_acc'], 'test': h['final_test_acc']} for name, h in results.items()}\n",
                "}\n",
                "\n",
                "save_metrics_json(os.path.join(OUTPUT_DIR, 'summary.json'), summary)\n",
                "df.to_csv(os.path.join(OUTPUT_DIR, 'scheduler_comparison.csv'), index=False)\n",
                "\n",
                "print(f\"\\nResults saved to {OUTPUT_DIR}/\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}