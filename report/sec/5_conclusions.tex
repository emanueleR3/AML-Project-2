\section{Conclusion}
\label{sec:conclusion}

In this work, we investigated the problem of interference in Federated Learning under statistical heterogeneity through the lens of task composition. By interpreting each client update as a local task-specific adaptation of a shared pretrained model, we reframed client interference as the uncontrolled composition of heterogeneous adaptations. This perspective naturally motivated the use of sparse fine-tuning as a structural mechanism to limit conflicting updates during aggregation.

Through extensive experiments on CIFAR-100 using a pretrained DINO ViT-S/16 backbone, we showed that restricting updates to a globally coordinated subset of parameters can improve robustness in strongly non-IID settings. In particular, sparse fine-tuning consistently mitigated the performance degradation observed in standard FedAvg as data heterogeneity increased, highlighting a clear trade-off between plasticity and stability. Our ablation studies further indicated that moderate sparsity levels and a small number of Fisher calibration rounds are sufficient to obtain stable performance, suggesting that sensitivity-based masking can be implemented with limited overhead.

Beyond performance improvements, our results provide insight into the nature of interference in federated optimization. The comparable performance observed across different masking rules suggests that the key factor in reducing interference is not solely the precise criterion used to select parameters, but rather the imposition of a shared structural constraint on model adaptation. From this perspective, global sparsity acts as a coordination mechanism among clients, ensuring that local updates remain compatible during aggregation despite heterogeneous data distributions.

This study has several limitations. Our evaluation is restricted to a single dataset, backbone architecture, and single-seed experiments, which limits the statistical strength and generality of our conclusions. Additionally, the relative effectiveness of different masking strategies warrants further investigation under broader experimental conditions.

Future work will focus on extending this analysis to larger-scale backbones, multi-seed evaluations, and more realistic federated benchmarks. Exploring adaptive or client-aware sparsity mechanisms and analyzing communication-efficiency trade-offs also represent promising directions. Overall, our findings suggest that mitigating interference in Federated Learning may benefit less from increasingly complex optimization schemes and more from controlling which parts of a pretrained model are allowed to adapt in heterogeneous federated environments.
