\section{Introduction}
\label{sec:intro}

The proliferation of edge devices and growing privacy concerns have driven the adoption of Federated Learning (FL) as a paradigm for training machine learning models on decentralized data~\cite{mcmahan2017communication}. By keeping data local and sharing only model updates, FL enables collaborative learning while respecting user privacy. However, this distributed setting introduces a fundamental challenge: client data is rarely independent and identically distributed (IID). In practice, users generate data that reflects their individual behaviours, preferences, and environments, leading to significant statistical heterogeneity across the federation~\cite{kairouz2021advances}.

This heterogeneity has profound implications for model training. When clients optimize on their local distributions, their updates can point in conflicting directions, a phenomenon known as ``client drift''~\cite{karimireddy2020scaffold}. Upon aggregation, these divergent updates interfere with one another, slowing convergence and degrading the quality of the global model. The more heterogeneous the data, the more severe this interference becomes, often rendering standard federated algorithms ineffective in real-world deployments~\cite{hsu2019measuring}.

Recent advances in model editing and task arithmetic have revealed a promising direction for addressing such interference~\cite{iurada2025efficient}. The key insight is that not all parameters contribute equally to a model's knowledge: some are highly specialized to specific tasks, while others are more general. By identifying and selectively updating only certain parameters during fine-tuning, it becomes possible to adapt models to new tasks while preserving their original capabilities. This principle of \emph{sparse fine-tuning} has shown remarkable success in mitigating interference when composing knowledge from multiple sources.

In this work, we bring these insights from model editing into the Federated Learning domain. We propose that the interference caused by heterogeneous client updates can be viewed through the lens of task composition: each client essentially fine-tunes the global model on their local ``task.'' By restricting updates to parameters that are least sensitive to the pretrained knowledge, we aim to reduce the conflicts that arise during aggregation. This approach offers a principled way to leverage powerful pretrained representations while maintaining the collaborative benefits of federated learning.

We evaluate our approach on the CIFAR-100 image classification benchmark using a pretrained Vision Transformer backbone. Through comprehensive experiments, we compare our sparse fine-tuning strategy against standard federated baselines under varying degrees of data heterogeneity. We further explore different criteria for selecting which parameters to update, providing insights into the relationship between parameter sensitivity and client drift mitigation.

\subsection{Contributions}

Our main contributions are as follows:
\begin{itemize}
    \item We establish centralized and federated baselines using pretrained Vision Transformer features, providing a solid foundation for comparison.
    \item We integrate sparse fine-tuning into the Federated Learning loop through gradient masking based on parameter sensitivity, enabling selective updates that preserve pretrained knowledge.
    \item We conduct ablation studies to understand the impact of key hyperparameters, including sparsity levels and mask calibration strategies.
    \item We compare multiple parameter selection criteria and analyze their effectiveness under severe data heterogeneity, offering practical guidance for practitioners.
\end{itemize}

The remainder of this paper is organized as follows: Section~\ref{sec:related} reviews related work. Section~\ref{sec:method} describes our methodology. Section~\ref{sec:experiments} presents our experimental evaluation. Section~\ref{sec:conclusion} concludes with a discussion of findings and future directions.