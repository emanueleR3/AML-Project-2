\begin{abstract}
Federated Learning (FL) enables collaborative model training across distributed clients without sharing raw data, preserving privacy by design. However, statistical heterogeneity, where clients have non-identically distributed data, remains a major challenge, causing interference during model aggregation and degrading global performance. 
In this work, we investigate the application of sparse fine-tuning techniques to address data heterogeneity in Federated Learning. Using a pretrained Vision Transformer backbone on the CIFAR-100 dataset, we implement a federated framework following the FedAvg protocol and introduce a gradient masking mechanism based on Fisher Information sensitivity scores. This approach restricts local updates to parameters that are least sensitive to pretrained knowledge, aiming to reduce interference between clients.
We conduct extensive experiments comparing centralized and federated baselines under various data heterogeneity conditions, and evaluate five different masking strategies. Our ablation studies examine the effects of calibration rounds and sparsity levels on model convergence. Results demonstrate that sparse fine-tuning can improve generalization under severe data heterogeneity, providing insights into the trade-offs between sparsity and model robustness in federated settings.
\end{abstract}