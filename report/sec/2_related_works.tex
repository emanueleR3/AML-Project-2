
\section{Related Works}
\label{sec:related}

Federated Learning (FL) has emerged as a critical paradigm for decentralized machine learning, enabling the training of models across distributed devices without sharing raw data, thereby embodying principles of data minimization~\cite{mcmahan2017communication}. However, practical FL deployments face significant hurdles regarding statistical heterogeneity (non-IID data) and system heterogeneity (varying computational resources). This section reviews the foundational algorithms, optimization strategies, and architectural considerations developed to address these challenges.

\subsection{Foundations and Heterogeneity Challenges}

The standard algorithm for FL is Federated Averaging (FedAvg), introduced by McMahan~\etal~\cite{mcmahan2017communication}. FedAvg aggregates locally computed updates (via Stochastic Gradient Descent) from participating clients to refine a shared global model. While FedAvg has proven robust in various settings, its performance degrades significantly when client data is not independent and identically distributed (non-IID) or when data quantities are unbalanced~\cite{mcmahan2017communication}.

Kairouz~\etal~\cite{kairouz2021advances} provide a comprehensive taxonomy of these challenges, identifying non-IID data and system constraints (such as bandwidth and device availability) as primary obstacles to FL scalability. To address heterogeneity, Li~\etal~\cite{li2020federated} proposed FedProx. This framework generalizes FedAvg by introducing a proximal term to the local objective function. This term restricts the deviation of local updates from the global model, thereby improving convergence stability in scenarios characterized by both statistical and systems heterogeneity.

\subsection{Advanced Optimization Algorithms}

A major issue caused by statistical heterogeneity is ``client-drift,'' where local updates move towards local optima rather than the global optimum. To mitigate this, Karimireddy~\etal~\cite{karimireddy2020scaffold} introduced SCAFFOLD (Stochastic Controlled Averaging). SCAFFOLD utilizes control variates (variance reduction) to estimate the update direction of the server and clients, correcting the drift in local updates. Theoretical analysis and experiments demonstrate that SCAFFOLD requires significantly fewer communication rounds compared to FedAvg and is resilient to client sampling.

In parallel, Reddi~\etal~\cite{reddi2021adaptive} proposed a framework for Adaptive Federated Optimization. While FedAvg effectively uses SGD on the server side, adaptive optimizers like Adam, Adagrad, and Yogi can be adapted for the server update step. Algorithms such as FedAdam, FedYogi, and FedAdagrad apply adaptive learning rates to the aggregated server updates, which helps in settings with sparse gradients or heavy-tail noise distributions, common in language and text tasks.

\subsection{Handling Feature Shifts and Architecture Design}

While optimization algorithms tackle weight updates, other approaches focus on the model architecture's response to distribution shifts. For scenarios where data heterogeneity manifests as feature shifts (\eg, different visual appearances due to different acquisition devices), Li~\etal~\cite{li2021fedbn} proposed FedBN. FedBN keeps Batch Normalization (BN) parameters local to each client rather than aggregating them on the server. This strategy mitigates feature shifts and has been shown to outperform FedAvg and FedProx in non-IID benchmarks.

Recent work by Qu~\etal~\cite{qu2022rethinking} investigates the impact of the backbone architecture itself, comparing Convolutional Neural Networks (CNNs) with Vision Transformers (ViTs) in federated settings. Their findings suggest that self-attention-based architectures are inherently more robust to distribution shifts and severe occlusions than CNNs. Consequently, replacing CNNs with Transformers can reduce catastrophic forgetting and accelerate convergence in heterogeneous environments.

\subsection{Data Distribution and Realistic Benchmarks}

Understanding the nature of non-IID data is crucial. Hsu~\etal~\cite{hsu2019measuring} analyzed the effects of non-identical distributions by synthesizing datasets using Dirichlet distributions to control heterogeneity. They observed that as data becomes more non-identical, the accuracy of FedAvg degrades, and proposed FedAvgM (FedAvg with Server Momentum) as a mitigation strategy.

Further extending this to real-world scenarios, Hsu~\etal~\cite{hsu2020federated} introduced large-scale benchmarks derived from datasets like iNaturalist and Google Landmarks, which feature natural user-based partitions. They proposed two algorithms to handle the long-tailed class distributions and data imbalance found in the wild: FedIR (Importance Reweighting), which applies importance weights to local objectives, and FedVC (Virtual Clients), which resamples and splits clients to normalize resource utilization.

\subsection{Privacy and System Constraints}

Finally, the implementation of FL must respect privacy and fairness constraints. Chen~\etal~\cite{chen2023privacy} highlight the trade-offs between privacy and fairness, noting that while FL protects data locality, the resulting models must be carefully tuned to avoid bias against specific demographic groups. Additionally, Pfeiffer~\etal~\cite{pfeiffer2023federated} survey the challenges of computationally constrained devices, categorizing heterogeneity into hard constraints (\eg, memory) and soft constraints (\eg, training speed). They emphasize that dealing with stragglers and heterogeneous device capabilities often requires asynchronous aggregation or specialized model splitting techniques like Split Learning.

\subsection{Task-Localized Sparse Fine-tuning}

Recent advances in efficient model editing have shown that sparse fine-tuning can effectively update pretrained models while preserving knowledge. Iurada~\etal~\cite{iurada2025efficient} proposed a task-localized sparse fine-tuning approach that identifies and updates only a subset of parameters most relevant to a given task. This paradigm leverages Fisher Information scores to identify parameter sensitivity, enabling efficient adaptation with minimal interference to existing knowledge. Such techniques are particularly relevant for federated learning settings, where communication efficiency and computational constraints are paramount concerns.